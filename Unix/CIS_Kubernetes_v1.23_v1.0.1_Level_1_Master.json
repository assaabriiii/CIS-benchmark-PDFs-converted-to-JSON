{
    "custom_item_1": {
        "description": "Check if kubelet is running",
        "name": "kubelet"
    },
    "custom_item_2": {
        "description": "Check if this is a Docker Vessel/Host",
        "cmd": "/usr/bin/docker info; /usr/bin/containerd --version",
        "expect": "(Containers|containerd)"
    },
    "custom_item_3": {
        "description": "Check if API Server is running",
        "name": "kube-apiserver"
    },
    "custom_item_4": {
        "system": "Linux",
        "description": "1.1.1 Ensure that the API server pod specification file permissions are set to 600 or more restrictive",
        "info": "Ensure that the API server pod specification file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe API server pod specification file controls various parameters that set the behavior of the API server. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/manifests/kube-apiserver.yaml\n\nDefault Value:\n\nBy default, the kube-apiserver.yaml file has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@APISERVER_FILE@",
        "mask": "177"
    },
    "custom_item_5": {
        "system": "Linux",
        "description": "1.1.2 Ensure that the API server pod specification file ownership is set to root:root",
        "info": "Ensure that the API server pod specification file ownership is set to root:root.\n\nRationale:\n\nThe API server pod specification file controls various parameters that set the behavior of the API server. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/manifests/kube-apiserver.yaml\n\nDefault Value:\n\nBy default, the kube-apiserver.yaml file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@APISERVER_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_6": {
        "description": "Check if Controller Manager is running",
        "name": "kube-controller"
    },
    "custom_item_7": {
        "system": "Linux",
        "description": "1.1.3 Ensure that the controller manager pod specification file permissions are set to 600 or more restrictive",
        "info": "Ensure that the controller manager pod specification file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe controller manager pod specification file controls various parameters that set the behavior of the Controller Manager on the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/manifests/kube-controller-manager.yaml\n\nDefault Value:\n\nBy default, the kube-controller-manager.yaml file has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@CONTROLLER_MANAGER_CONFIG_FILE@",
        "mask": "177"
    },
    "custom_item_8": {
        "system": "Linux",
        "description": "1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root",
        "info": "Ensure that the controller manager pod specification file ownership is set to root:root.\n\nRationale:\n\nThe controller manager pod specification file controls various parameters that set the behavior of various components of the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/manifests/kube-controller-manager.yaml\n\nDefault Value:\n\nBy default, kube-controller-manager.yaml file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@CONTROLLER_MANAGER_CONFIG_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_9": {
        "description": "Check if Scheduler is running",
        "name": "kube-scheduler"
    },
    "custom_item_10": {
        "system": "Linux",
        "description": "1.1.5 Ensure that the scheduler pod specification file permissions are set to 600 or more restrictive",
        "info": "Ensure that the scheduler pod specification file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe scheduler pod specification file controls various parameters that set the behavior of the Scheduler service in the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/manifests/kube-scheduler.yaml\n\nDefault Value:\n\nBy default, kube-scheduler.yaml file has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@SCHEDULER_FILE@",
        "mask": "177"
    },
    "custom_item_11": {
        "system": "Linux",
        "description": "1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root",
        "info": "Ensure that the scheduler pod specification file ownership is set to root:root.\n\nRationale:\n\nThe scheduler pod specification file controls various parameters that set the behavior of the kube-scheduler service in the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/manifests/kube-scheduler.yaml\n\nDefault Value:\n\nBy default, kube-scheduler.yaml file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@SCHEDULER_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_12": {
        "description": "Check if etcd is running",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "etcd[2]?[\\\\s]"
    },
    "custom_item_13": {
        "system": "Linux",
        "description": "1.1.7 Ensure that the etcd pod specification file permissions are set to 600 or more restrictive",
        "info": "Ensure that the /etc/kubernetes/manifests/etcd.yaml file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe etcd pod specification file /etc/kubernetes/manifests/etcd.yaml controls various parameters that set the behavior of the etcd service in the master node. etcd is a highly-available key-value store which Kubernetes uses for persistent storage of all of its REST API object. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/manifests/etcd.yaml\n\nDefault Value:\n\nBy default, /etc/kubernetes/manifests/etcd.yaml file has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ETCD_CONF_FILE@",
        "mask": "177"
    },
    "custom_item_14": {
        "system": "Linux",
        "description": "1.1.8 Ensure that the etcd pod specification file ownership is set to root:root",
        "info": "Ensure that the /etc/kubernetes/manifests/etcd.yaml file ownership is set to root:root.\n\nRationale:\n\nThe etcd pod specification file /etc/kubernetes/manifests/etcd.yaml controls various parameters that set the behavior of the etcd service in the master node. etcd is a highly-available key-value store which Kubernetes uses for persistent storage of all of its REST API object. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/manifests/etcd.yaml\n\nDefault Value:\n\nBy default, /etc/kubernetes/manifests/etcd.yaml file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ETCD_CONF_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_15": {
        "description": "Check if flanneld file exists",
        "file": "@FLANNELD_FILE@"
    },
    "custom_item_16": {
        "system": "Linux",
        "description": "1.1.9 Ensure that the Container Network Interface file permissions are set to 600 or more restrictive",
        "info": "Ensure that the Container Network Interface files have permissions of 600 or more restrictive.\n\nRationale:\n\nContainer Network Interface provides various networking options for overlay networking. You should consult their documentation and restrict their respective file permissions to maintain the integrity of those files. Those files should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600Default Value:\n\nNA",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1M,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@FLANNELD_FILE@",
        "mask": "177"
    },
    "custom_item_17": {
        "system": "Linux",
        "description": "1.1.10 Ensure that the Container Network Interface file ownership is set to root:root",
        "info": "Ensure that the Container Network Interface files have ownership set to root:root.\n\nRationale:\n\nContainer Network Interface provides various networking options for overlay networking. You should consult their documentation and restrict their respective file permissions to maintain the integrity of those files. Those files should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:rootDefault Value:\n\nNA",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@FLANNELD_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_18": {
        "description": "Check if etcd is running",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "etcd[2]?[\\\\s]"
    },
    "custom_item_19": {
        "system": "Linux",
        "description": "1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive",
        "info": "Ensure that the etcd data directory has permissions of 700 or more restrictive.\n\nRationale:\n\netcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should not be readable or writable by any group members or the world.\n\nImpact:\n\nNone",
        "solution": "On the etcd server node, get the etcd data directory, passed as an argument --data-dir, from the below command:\n\nps -ef | grep etcd\n\nRun the below command (based on the etcd data directory found above). For example,\n\nchmod 700 /var/lib/etcd\n\nDefault Value:\n\nBy default, etcd data directory has permissions of 755.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ETCD_DATA_DIR@",
        "mask": "077"
    },
    "custom_item_20": {
        "system": "Linux",
        "description": "1.1.12 Ensure that the etcd data directory ownership is set to etcd:etcd",
        "info": "Ensure that the etcd data directory ownership is set to etcd:etcd.\n\nRationale:\n\netcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should be owned by etcd:etcd.\n\nImpact:\n\nNone",
        "solution": "On the etcd server node, get the etcd data directory, passed as an argument --data-dir, from the below command:\n\nps -ef | grep etcd\n\nRun the below command (based on the etcd data directory found above). For example,\n\nchown etcd:etcd /var/lib/etcd\n\nDefault Value:\n\nBy default, etcd data directory ownership is set to etcd:etcd.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|16,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ETCD_DATA_DIR@",
        "owner": "etcd",
        "group": "etcd"
    },
    "custom_item_21": {
        "system": "Linux",
        "description": "1.1.13 Ensure that the admin.conf file permissions are set to 600",
        "info": "Ensure that the admin.conf file has permissions of 600.\n\nRationale:\n\nThe admin.conf is the administrator kubeconfig file defining various settings for the administration of the cluster. This file contains private key and respective certificate allowed to fully manage the cluster. You should restrict its file permissions to maintain the integrity and confidentiality of the file. The file should be readable and writable by only the administrators on the system.\n\nImpact:\n\nNone.",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/admin.conf\n\nDefault Value:\n\nBy default, admin.conf has permissions of 600.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ADMIN_KUBECONFIG_FILE@",
        "mask": "177"
    },
    "custom_item_22": {
        "system": "Linux",
        "description": "1.1.14 Ensure that the admin.conf file ownership is set to root:root",
        "info": "Ensure that the admin.conf file ownership is set to root:root.\n\nRationale:\n\nThe admin.conf file contains the admin credentials for the cluster. You should set its file ownership to maintain the integrity and confidentiality of the file. The file should be owned by root:root.\n\nImpact:\n\nNone.",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/admin.conf\n\nDefault Value:\n\nBy default, admin.conf file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ADMIN_KUBECONFIG_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_23": {
        "system": "Linux",
        "description": "1.1.15 Ensure that the scheduler.conf file permissions are set to 600 or more restrictive",
        "info": "Ensure that the scheduler.conf file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe scheduler.conf file is the kubeconfig file for the Scheduler. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/scheduler.conf\n\nDefault Value:\n\nBy default, scheduler.conf has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@SCHEDULER_KUBECONFIG_FILE@",
        "mask": "177"
    },
    "custom_item_24": {
        "system": "Linux",
        "description": "1.1.16 Ensure that the scheduler.conf file ownership is set to root:root",
        "info": "Ensure that the scheduler.conf file ownership is set to root:root.\n\nRationale:\n\nThe scheduler.conf file is the kubeconfig file for the Scheduler. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/scheduler.conf\n\nDefault Value:\n\nBy default, scheduler.conf file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@SCHEDULER_KUBECONFIG_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_25": {
        "system": "Linux",
        "description": "1.1.17 Ensure that the controller-manager.conf file permissions are set to 600 or more restrictive",
        "info": "Ensure that the controller-manager.conf file has permissions of 600 or more restrictive.\n\nRationale:\n\nThe controller-manager.conf file is the kubeconfig file for the Controller Manager. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod 600 /etc/kubernetes/controller-manager.conf\n\nDefault Value:\n\nBy default, controller-manager.conf has permissions of 640.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@CONTROLLER_MANAGER_KUBECONFIG_FILE@",
        "mask": "177"
    },
    "custom_item_26": {
        "system": "Linux",
        "description": "1.1.18 Ensure that the controller-manager.conf file ownership is set to root:root",
        "info": "Ensure that the controller-manager.conf file ownership is set to root:root.\n\nRationale:\n\nThe controller-manager.conf file is the kubeconfig file for the Controller Manager. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown root:root /etc/kubernetes/controller-manager.conf\n\nDefault Value:\n\nBy default, controller-manager.conf file ownership is set to root:root.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@CONTROLLER_MANAGER_KUBECONFIG_FILE@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_27": {
        "system": "Linux",
        "description": "1.1.19 Ensure that the Kubernetes PKI directory and file ownership is set to root:root",
        "info": "Ensure that the Kubernetes PKI directory and file ownership is set to root:root.\n\nRationale:\n\nKubernetes makes use of a number of certificates as part of its operation. You should set the ownership of the directory containing the PKI information and all files in that directory to maintain their integrity. The directory and files should be owned by root:root.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchown -R root:root /etc/kubernetes/pki/\n\nDefault Value:\n\nBy default, the /etc/kubernetes/pki/ directory and all of the files and directories contained within it, are set to be owned by the root user.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@PKI_DIRECTORY@",
        "owner": "root",
        "group": "root"
    },
    "custom_item_28": {
        "system": "Linux",
        "description": "1.1.20 Ensure that the Kubernetes PKI certificate file permissions are set to 600 or more restrictive",
        "info": "Ensure that Kubernetes PKI certificate files have permissions of 600 or more restrictive.\n\nRationale:\n\nKubernetes makes use of a number of certificate files as part of the operation of its components. The permissions on these files should be set to 600 or more restrictive to protect their integrity.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod -R 600 /etc/kubernetes/pki/*.crt\n\nDefault Value:\n\nBy default, the certificates used by Kubernetes are set to have permissions of 644",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@PKI_DIRECTORY@/*.crt",
        "mask": "177"
    },
    "custom_item_29": {
        "system": "Linux",
        "description": "1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600",
        "info": "Ensure that Kubernetes PKI key files have permissions of 600.\n\nRationale:\n\nKubernetes makes use of a number of key files as part of the operation of its components. The permissions on these files should be set to 600 to protect their integrity and confidentiality.\n\nImpact:\n\nNone",
        "solution": "Run the below command (based on the file location on your system) on the Control Plane node. For example,\n\nchmod -R 600 /etc/kubernetes/pki/*.key\n\nDefault Value:\n\nBy default, the keys used by Kubernetes are set to have permissions of 600",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1M,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@PKI_DIRECTORY@/*.key",
        "mask": "177"
    },
    "custom_item_30": {
        "description": "Check if API Server is running",
        "name": "kube-apiserver"
    },
    "custom_item_31": {
        "system": "Linux",
        "description": "1.2.1 Ensure that the --anonymous-auth argument is set to false",
        "info": "Disable anonymous requests to the API server.\n\nRationale:\n\nWhen enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the API server. You should rely on authentication to authorize access and disallow anonymous requests.\n\nIf you are using RBAC authorization, it is generally considered reasonable to allow anonymous access to the API Server for health checks and discovery purposes, and hence this recommendation is not scored. However, you should consider whether anonymous discovery is an acceptable risk for your purposes.\n\nImpact:\n\nAnonymous requests will be rejected.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n--anonymous-auth=false\n\nDefault Value:\n\nBy default, anonymous access is enabled.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1M,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--anonymous-auth=false"
    },
    "custom_item_32": {
        "system": "Linux",
        "description": "1.2.2 Ensure that the --token-auth-file parameter is not set",
        "info": "Do not use token based authentication.\n\nRationale:\n\nThe token-based authentication utilizes static tokens to authenticate requests to the apiserver. The tokens are stored in clear-text in a file on the apiserver, and cannot be revoked or rotated without restarting the apiserver. Hence, do not use static token-based authentication.\n\nImpact:\n\nYou will have to configure and use alternate authentication mechanisms such as certificates. Static token based authentication could not be used.",
        "solution": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and remove the --token-auth-file=parameter.\n\nDefault Value:\n\nBy default, --token-auth-file argument is not set.",
        "reference": "800-171|3.4.6,800-171|3.4.7,800-171|3.7.5,800-53|CM-7,800-53|MA-4,800-53r5|CM-7,800-53r5|MA-4,CSCv7|16.4,CSCv8|4.6,CSF|PR.IP-1,CSF|PR.MA-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-7,ITSG-33|MA-4,LEVEL|1A,NESA|T2.3.4,NESA|T5.4.4,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,QCSC-v1|5.2.2,SWIFT-CSCv1|2.3,TBA-FIISB|45.2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "^((?!--token-auth-file).)*$"
    },
    "custom_item_33": {
        "description": "1.2.3 Ensure that the --DenyServiceExternalIPs is not set",
        "info": "This admission controller rejects all net-new usage of the Service field externalIPs.\n\nRationale:\n\nThis admission controller rejects all net-new usage of the Service field externalIPs. This feature is very powerful (allows network traffic interception) and not well controlled by policy. When enabled, users of the cluster may not create new Services which use externalIPs and may not add new values to externalIPs on existing Service objects. Existing uses of externalIPs are not affected, and users may remove values from externalIPs on existing Service objects.\n\nMost users do not need this feature at all, and cluster admins should consider disabling it. Clusters that do need to use this feature should consider using some custom policy to manage usage of it.\n\nImpact:\n\nWhen enabled, users of the cluster may not create new Services which use externalIPs and may not add new values to externalIPs on existing Service objects.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and remove the '--DenyServiceExternalIPs'parameter\nor\nThe Kubernetes API server flag disable-admission-plugins takes a comma-delimited list of admission control plugins to be disabled, even if they are in the list of plugins enabled by default.\nkube-apiserver --disable-admission-plugins=DenyServiceExternalIPs,AlwaysDeny ...\n\nDefault Value:\n\nBy default, --token-auth-file argument is not set.",
        "reference": "800-171|3.4.6,800-171|3.4.7,800-171|3.7.5,800-53|CM-7,800-53|MA-4,800-53r5|CM-7,800-53r5|MA-4,CSCv7|16.4,CSCv8|4.6,CSF|PR.IP-1,CSF|PR.MA-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-7,ITSG-33|MA-4,LEVEL|1A,NESA|T2.3.4,NESA|T5.4.4,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,QCSC-v1|5.2.2,SWIFT-CSCv1|2.3,TBA-FIISB|45.2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "^((?!--DenyServiceExternalIPs).)*$"
    },
    "custom_item_34": {
        "system": "Linux",
        "description": "1.2.4 Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate - certificate",
        "info": "Enable certificate based kubelet authentication.\n\nRationale:\n\nThe apiserver, by default, does not authenticate itself to the kubelet's HTTPS endpoints. The requests from the apiserver are treated anonymously. You should set up certificate-based kubelet authentication to ensure that the apiserver authenticates itself to kubelets when submitting requests.\n\nImpact:\n\nYou require TLS to be configured on apiserver as well as kubelets.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the kubelet client certificate and key parameters as below.\n\n--kubelet-client-certificate=--kubelet-client-key=Default Value:\n\nBy default, certificate-based kubelet authentication is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1A,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--kubelet-client-certificate=@KUBELET_CLIENT_CERTIFICATE@([\\\\s]|$)"
    },
    "custom_item_35": {
        "system": "Linux",
        "description": "1.2.4 Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate - key",
        "info": "Enable certificate based kubelet authentication.\n\nRationale:\n\nThe apiserver, by default, does not authenticate itself to the kubelet's HTTPS endpoints. The requests from the apiserver are treated anonymously. You should set up certificate-based kubelet authentication to ensure that the apiserver authenticates itself to kubelets when submitting requests.\n\nImpact:\n\nYou require TLS to be configured on apiserver as well as kubelets.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the kubelet client certificate and key parameters as below.\n\n--kubelet-client-certificate=--kubelet-client-key=Default Value:\n\nBy default, certificate-based kubelet authentication is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1A,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--kubelet-client-key=@KUBELET_CLIENT_KEY@([\\\\s]|$)"
    },
    "custom_item_36": {
        "system": "Linux",
        "description": "1.2.5 Ensure that the --kubelet-certificate-authority argument is set as appropriate",
        "info": "Verify kubelet's certificate before establishing connection.\n\nRationale:\n\nThe connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet's port-forwarding functionality. These connections terminate at the kubelet's HTTPS endpoint. By default, the apiserver does not verify the kubelet's serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.\n\nImpact:\n\nYou require TLS to be configured on apiserver as well as kubelets.",
        "solution": "Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --kubelet-certificate-authority parameter to the path to the cert file for the certificate authority.\n\n--kubelet-certificate-authority=Default Value:\n\nBy default, --kubelet-certificate-authority argument is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1A,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--kubelet-certificate-authority=@KUBELET_CERTIFICATE_AUTHORITY@([\\\\s]|$)"
    },
    "custom_item_37": {
        "system": "Linux",
        "description": "1.2.6 Ensure that the --authorization-mode argument is not set to AlwaysAllow",
        "info": "Do not always authorize all requests.\n\nRationale:\n\nThe API Server, can be configured to allow all requests. This mode should not be used on any production cluster.\n\nImpact:\n\nOnly authorized requests will be served.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to values other than AlwaysAllow. One such example could be as below.\n\n--authorization-mode=RBAC\n\nDefault Value:\n\nBy default, AlwaysAllow is not enabled.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|9.2,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--authorization-mode=((?!AlwaysAllow).)*([\\\\s]|$)"
    },
    "custom_item_38": {
        "system": "Linux",
        "description": "1.2.7 Ensure that the --authorization-mode argument includes Node",
        "info": "Restrict kubelet nodes to reading only objects associated with them.\n\nRationale:\n\nThe Node authorization mode only allows kubelets to read Secret, ConfigMap, PersistentVolume, and PersistentVolumeClaim objects associated with their nodes.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to a value that includes Node.\n\n--authorization-mode=Node,RBAC\n\nDefault Value:\n\nBy default, Node authorization is not enabled.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|9.2,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--authorization-mode=[A-z,]*Node[A-z,]*([\\\\s]|$)"
    },
    "custom_item_39": {
        "system": "Linux",
        "description": "1.2.8 Ensure that the --authorization-mode argument includes RBAC",
        "info": "Turn on Role Based Access Control.\n\nRationale:\n\nRole Based Access Control (RBAC) allows fine-grained control over the operations that different entities can perform on different objects in the cluster. It is recommended to use the RBAC authorization mode.\n\nImpact:\n\nWhen RBAC is enabled you will need to ensure that appropriate RBAC settings (including Roles, RoleBindings and ClusterRoleBindings) are configured to allow appropriate access.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --authorization-mode parameter to a value that includes RBAC, for example:\n\n--authorization-mode=Node,RBAC\n\nDefault Value:\n\nBy default, RBAC authorization is not enabled.",
        "reference": "800-171|3.1.1,800-171|3.1.5,800-171|3.3.8,800-171|3.3.9,800-53|AC-2,800-53|AC-3,800-53|AC-6,800-53|AC-6(1),800-53|AC-6(7),800-53|AU-9(4),800-53r5|AC-2,800-53r5|AC-3,800-53r5|AC-6,800-53r5|AC-6(1),800-53r5|AC-6(7),800-53r5|AU-9(4),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(d),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.3(d),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|6.8,CSF|DE.CM-1,CSF|DE.CM-3,CSF|PR.AC-1,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(b),ISO/IEC-27001|A.9.2.1,ISO/IEC-27001|A.9.2.5,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.4,ISO/IEC-27001|A.9.4.5,ISO/IEC-27001|A.12.4.2,ITSG-33|AC-2,ITSG-33|AC-3,ITSG-33|AC-6,ITSG-33|AC-6(1),ITSG-33|AU-9(4),ITSG-33|AU-9(4)(a),ITSG-33|AU-9(4)(b),LEVEL|1A,NESA|M1.1.3,NESA|M1.2.2,NESA|M5.2.3,NESA|M5.5.2,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|AM28,NIAv2|AM31,NIAv2|GS3,NIAv2|GS4,NIAv2|GS8c,NIAv2|NS5j,NIAv2|SM5,NIAv2|SM6,NIAv2|SS13c,NIAv2|SS14e,NIAv2|SS15c,NIAv2|SS29,NIAv2|VL3b,PCI-DSSv3.2.1|7.1.2,PCI-DSSv3.2.1|10.5,PCI-DSSv3.2.1|10.5.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,PCI-DSSv4.0|10.3.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|13.2,QCSC-v1|15.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--authorization-mode=[A-z,]*RBAC[A-z,]*([\\\\s]|$)"
    },
    "custom_item_40": {
        "system": "Linux",
        "description": "1.2.9 Ensure that the admission control plugin EventRateLimit is set",
        "info": "Limit the rate at which the API server accepts requests.\n\nRationale:\n\nUsing EventRateLimit admission control enforces a limit on the number of events that the API Server will accept in a given time slice. A misbehaving workload could overwhelm and DoS the API Server, making it unavailable. This particularly applies to a multi-tenant cluster, where there might be a small percentage of misbehaving tenants which could have a significant impact on the performance of the cluster overall. Hence, it is recommended to limit the rate of events that the API server will accept.\n\nNote: This is an Alpha feature in the Kubernetes 1.15 release.\n\nImpact:\n\nYou need to carefully tune in limits as per your environment.",
        "solution": "Follow the Kubernetes documentation and set the desired limits in a configuration file.\nThen, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml and set the below parameters.\n\n--enable-admission-plugins=...,EventRateLimit,...\n--admission-control-config-file=Default Value:\n\nBy default, EventRateLimit is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|8.3,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1M,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=[A-z,]*EventRateLimit[A-z,]*([\\\\s]|$)"
    },
    "custom_item_41": {
        "system": "Linux",
        "description": "1.2.10 Ensure that the admission control plugin AlwaysAdmit is not set",
        "info": "Do not allow all requests.\n\nRationale:\n\nSetting admission control plugin AlwaysAdmit allows all requests and do not filter any requests.\n\nThe AlwaysAdmit admission controller was deprecated in Kubernetes v1.13. Its behavior was equivalent to turning off all admission controllers.\n\nImpact:\n\nOnly requests explicitly allowed by the admissions control plugins would be served.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and either remove the --enable-admission-plugins parameter, or set it to a value that does not include AlwaysAdmit.\n\nDefault Value:\n\nAlwaysAdmit is not in the list of default admission plugins.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=((?!AlwaysAdmit).)*([\\\\s]|$)"
    },
    "custom_item_42": {
        "system": "Linux",
        "description": "1.2.11 Ensure that the admission control plugin AlwaysPullImages is set",
        "info": "Always pull images.\n\nRationale:\n\nSetting admission control policy to AlwaysPullImages forces every new pod to pull the required images every time. In a multi-tenant cluster users can be assured that their private images can only be used by those who have the credentials to pull them. Without this admission control policy, once an image has been pulled to a node, any pod from any user can use it simply by knowing the image's name, without any authorization check against the image ownership. When this plug-in is enabled, images are always pulled prior to starting containers, which means valid credentials are required.\n\nImpact:\n\nCredentials would be required to pull the private images every time. Also, in trusted environments, this might increase load on network, registry, and decreases speed.\n\nThis setting could impact offline or isolated clusters, which have images pre-loaded and do not have access to a registry to pull in-use images. This setting is not appropriate for clusters which use this configuration.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include AlwaysPullImages.\n\n--enable-admission-plugins=...,AlwaysPullImages,...\n\nDefault Value:\n\nBy default, AlwaysPullImages is not set.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1M,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=[A-z,]*AlwaysPullImages[A-z,]*([\\\\s]|$)"
    },
    "custom_item_43": {
        "description": "enable-admission-plugins includes SecurityContextDeny",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=[A-z,]*SecurityContextDeny[A-z,]*([\\\\s]|$)"
    },
    "custom_item_44": {
        "system": "Linux",
        "description": "1.2.12 Ensure that the admission control plugin SecurityContextDeny is set if PodSecurityPolicy is not used",
        "info": "The SecurityContextDeny admission controller can be used to deny pods which make use of some SecurityContext fields which could allow for privilege escalation in the cluster. This should be used where PodSecurityPolicy is not in place within the cluster.\n\nRationale:\n\nSecurityContextDeny can be used to provide a layer of security for clusters which do not have PodSecurityPolicies enabled.\n\nImpact:\n\nThis admission controller should only be used where Pod Security Policies cannot be used on the cluster, as it can interact poorly with certain Pod Security Policies",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include SecurityContextDeny, unless PodSecurityPolicy is already in place.\n\n--enable-admission-plugins=...,SecurityContextDeny,...\n\nDefault Value:\n\nBy default, SecurityContextDeny is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1M,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=[A-z,]*SecurityContextDeny[A-z,]*([\\\\s]|$)"
    },
    "custom_item_45": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_46": {
        "system": "Linux",
        "description": "1.2.12 Ensure that the admission control plugin SecurityContextDeny is set if PodSecurityPolicy is not used",
        "info": "The SecurityContextDeny admission controller can be used to deny pods which make use of some SecurityContext fields which could allow for privilege escalation in the cluster. This should be used where PodSecurityPolicy is not in place within the cluster.\n\nRationale:\n\nSecurityContextDeny can be used to provide a layer of security for clusters which do not have PodSecurityPolicies enabled.\n\nImpact:\n\nThis admission controller should only be used where Pod Security Policies cannot be used on the cluster, as it can interact poorly with certain Pod Security Policies",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include SecurityContextDeny, unless PodSecurityPolicy is already in place.\n\n--enable-admission-plugins=...,SecurityContextDeny,...\n\nDefault Value:\n\nBy default, SecurityContextDeny is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1M,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ --all-namespaces",
        "expect": "^((?!No resources found).)*$"
    },
    "custom_item_47": {
        "system": "Linux",
        "description": "1.2.12 Ensure that the admission control plugin SecurityContextDeny is set if PodSecurityPolicy is not used",
        "info": "The SecurityContextDeny admission controller can be used to deny pods which make use of some SecurityContext fields which could allow for privilege escalation in the cluster. This should be used where PodSecurityPolicy is not in place within the cluster.\n\nRationale:\n\nSecurityContextDeny can be used to provide a layer of security for clusters which do not have PodSecurityPolicies enabled.\n\nImpact:\n\nThis admission controller should only be used where Pod Security Policies cannot be used on the cluster, as it can interact poorly with certain Pod Security Policies",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --enable-admission-plugins parameter to include SecurityContextDeny, unless PodSecurityPolicy is already in place.\n\n--enable-admission-plugins=...,SecurityContextDeny,...\n\nDefault Value:\n\nBy default, SecurityContextDeny is not set.",
        "reference": "800-53|SA-15,800-53r5|SA-15,CSCv7|9,CSCv8|16.11,CSF|PR.IP-2,GDPR|32.1.b,HIPAA|164.306(a)(1),LEVEL|1M,NIAv2|SS5,NIAv2|SS6a,QCSC-v1|4.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --all-namespaces",
        "expect": "^((?!No resources found).)*$"
    },
    "custom_item_48": {
        "system": "Linux",
        "description": "1.2.13 Ensure that the admission control plugin ServiceAccount is set",
        "info": "Automate service accounts management.\n\nRationale:\n\nWhen you create a pod, if you do not specify a service account, it is automatically assigned the default service account in the same namespace. You should create your own service account and let the API server manage its security tokens.\n\nImpact:\n\nNone.",
        "solution": "Follow the documentation and create ServiceAccount objects as per your environment. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and ensure that the --disable-admission-plugins parameter is set to a value that does not include ServiceAccount.\n\nDefault Value:\n\nBy default, ServiceAccount is set.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=((?!ServiceAccount).)*([\\\\s]|$)"
    },
    "custom_item_49": {
        "system": "Linux",
        "description": "1.2.14 Ensure that the admission control plugin NamespaceLifecycle is set",
        "info": "Reject creating objects in a namespace that is undergoing termination.\n\nRationale:\n\nSetting admission control policy to NamespaceLifecycle ensures that objects cannot be created in non-existent namespaces, and that namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --disable-admission-plugins parameter to ensure it does not include NamespaceLifecycle.\n\nDefault Value:\n\nBy default, NamespaceLifecycle is set.",
        "reference": "800-171|3.4.2,800-53|CM-6,800-53r5|CM-6,CSCv7|5.1,CSCv8|4,CSF|PR.IP-1,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,LEVEL|1A,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "^((?!--disable-admission-plugins=[A-z,]*NamespaceLifecycle[\\\\s,]).)*$"
    },
    "custom_item_50": {
        "system": "Linux",
        "description": "1.2.15 Ensure that the admission control plugin NodeRestriction is set",
        "info": "Limit the Node and Pod objects that a kubelet could modify.\n\nRationale:\n\nUsing the NodeRestriction plug-in ensures that the kubelet is restricted to the Node and Pod objects that it could modify as defined. Such kubelets will only be allowed to modify their own Node API object, and only modify Pod API objects that are bound to their node.\n\nImpact:\n\nNone",
        "solution": "Follow the Kubernetes documentation and configure NodeRestriction plug-in on kubelets. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --enable-admission-plugins parameter to a value that includes NodeRestriction.\n\n--enable-admission-plugins=...,NodeRestriction,...\n\nDefault Value:\n\nBy default, NodeRestriction is not set.",
        "reference": "800-171|3.13.1,800-53|SC-7(8),800-53r5|SC-7(8),CN-L3|8.1.10.6(j),CSCv7|12.9,CSCv8|13.10,CSF|PR.AC-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(8),LEVEL|1A,NESA|T4.5.4,NIAv2|SU4,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.2.1,PCI-DSSv4.0|1.4.1,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|43.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--enable-admission-plugins=[A-z,]*NodeRestriction[A-z,]*([\\\\s]|$)"
    },
    "custom_item_51": {
        "system": "Linux",
        "description": "1.2.16 Ensure that the --secure-port argument is not set to 0",
        "info": "Do not disable the secure port.\n\nRationale:\n\nThe secure port is used to serve https with authentication and authorization. If you disable it, no https traffic is served and all traffic is served unencrypted.\n\nImpact:\n\nYou need to set the API Server up with the right TLS certificates.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and either remove the --secure-port parameter or set it to a different (non-zero) desired port.\n\nDefault Value:\n\nBy default, port 6443 is used as the secure port.",
        "reference": "800-171|3.1.13,800-171|3.5.2,800-171|3.13.8,800-53|AC-17(2),800-53|IA-5,800-53|IA-5(1),800-53|SC-8,800-53|SC-8(1),800-53r5|AC-17(2),800-53r5|IA-5,800-53r5|IA-5(1),800-53r5|SC-8,800-53r5|SC-8(1),CN-L3|7.1.2.7(g),CN-L3|7.1.3.1(d),CN-L3|8.1.2.2(a),CN-L3|8.1.2.2(b),CN-L3|8.1.4.1(c),CN-L3|8.1.4.7(a),CN-L3|8.1.4.8(a),CN-L3|8.2.4.5(c),CN-L3|8.2.4.5(d),CN-L3|8.5.2.2,CSCv7|14.4,CSCv8|3.10,CSF|PR.AC-1,CSF|PR.AC-3,CSF|PR.DS-2,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),HIPAA|164.312(e)(1),HIPAA|164.312(e)(2)(i),ISO/IEC-27001|A.6.2.2,ISO/IEC-27001|A.10.1.1,ISO/IEC-27001|A.13.2.3,ITSG-33|AC-17(2),ITSG-33|IA-5,ITSG-33|IA-5(1),ITSG-33|SC-8,ITSG-33|SC-8a.,ITSG-33|SC-8(1),LEVEL|1A,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.2,NESA|T5.2.3,NESA|T5.4.2,NESA|T7.3.3,NESA|T7.4.1,NIAv2|AM37,NIAv2|IE8,NIAv2|IE9,NIAv2|IE12,NIAv2|NS5d,NIAv2|NS6b,NIAv2|NS29,NIAv2|SS24,PCI-DSSv3.2.1|2.3,PCI-DSSv3.2.1|4.1,PCI-DSSv4.0|2.2.7,PCI-DSSv4.0|4.2.1,QCSC-v1|3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|2.1,SWIFT-CSCv1|2.6,SWIFT-CSCv1|4.1,TBA-FIISB|29.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "(--secure-port=[1-9]|^((?!--secure-port).)*$)"
    },
    "custom_item_52": {
        "system": "Linux",
        "description": "1.2.17 Ensure that the --profiling argument is set to false",
        "info": "Disable profiling, if not needed.\n\nRationale:\n\nProfiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\n\nImpact:\n\nProfiling information would not be available.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n--profiling=false\n\nDefault Value:\n\nBy default, profiling is enabled.",
        "reference": "800-171|3.3.1,800-171|3.3.2,800-53|AU-6,800-53r5|AU-6,CN-L3|7.1.3.3(d),CSCv7|6,CSCv8|8,CSF|DE.AE-2,CSF|DE.AE-3,CSF|DE.DP-4,CSF|PR.PT-1,CSF|RS.AN-1,CSF|RS.CO-2,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-6,LEVEL|1A,NESA|M5.2.5,QCSC-v1|5.2.3,QCSC-v1|8.2.1,QCSC-v1|10.2.1,QCSC-v1|11.2,QCSC-v1|13.2,SWIFT-CSCv1|6.4",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--profiling=false"
    },
    "custom_item_53": {
        "system": "Linux",
        "description": "1.2.18 Ensure that the --audit-log-path argument is set",
        "info": "Enable auditing on the Kubernetes API Server and set the desired audit log path.\n\nRationale:\n\nAuditing the Kubernetes API Server provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --audit-log-path parameter to a suitable path and file where you would like audit logs to be written, for example:\n\n--audit-log-path=/var/log/apiserver/audit.log\n\nDefault Value:\n\nBy default, auditing is not enabled.",
        "reference": "800-171|3.3.1,800-171|3.3.2,800-171|3.3.6,800-53|AU-2,800-53|AU-7,800-53|AU-12,800-53r5|AU-2,800-53r5|AU-7,800-53r5|AU-12,CN-L3|7.1.2.3(c),CN-L3|8.1.4.3(a),CSCv7|6.2,CSCv8|8.2,CSF|DE.CM-1,CSF|DE.CM-3,CSF|DE.CM-7,CSF|PR.PT-1,CSF|RS.AN-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-2,ITSG-33|AU-7,ITSG-33|AU-12,LEVEL|1A,NESA|M1.2.2,NESA|M5.5.1,NIAv2|AM7,NIAv2|AM11a,NIAv2|AM11b,NIAv2|AM11c,NIAv2|AM11d,NIAv2|AM11e,NIAv2|SS30,NIAv2|VL8,PCI-DSSv3.2.1|10.1,QCSC-v1|3.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|10.2.1,QCSC-v1|11.2,QCSC-v1|13.2,SWIFT-CSCv1|6.4",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-log-path=@AUDIT_LOG_PATH@([\\\\s]|$)"
    },
    "custom_item_54": {
        "system": "Linux",
        "description": "1.2.19 Ensure that the --audit-log-maxage argument is set to 30 or as appropriate",
        "info": "Retain the logs for at least 30 days or as appropriate.\n\nRationale:\n\nRetaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --audit-log-maxage parameter to 30 or as an appropriate number of days:\n\n--audit-log-maxage=30\n\nDefault Value:\n\nBy default, auditing is not enabled.",
        "reference": "800-53|AU-4,800-53r5|AU-4,CSCv7|6.4,CSCv8|8.3,CSF|PR.DS-4,CSF|PR.PT-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-4,LEVEL|1A,NESA|T3.3.1,NESA|T3.6.2,QCSC-v1|8.2.1,QCSC-v1|13.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-log-maxage=@AUDIT_LOG_MAXAGE@([\\\\s]|$)"
    },
    "custom_item_55": {
        "system": "Linux",
        "description": "1.2.20 Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate",
        "info": "Retain 10 or an appropriate number of old log files.\n\nRationale:\n\nKubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --audit-log-maxbackup parameter to 10 or to an appropriate value.\n\n--audit-log-maxbackup=10\n\nDefault Value:\n\nBy default, auditing is not enabled.",
        "reference": "800-53|AU-4,800-53r5|AU-4,CSCv7|6.4,CSCv8|8.3,CSF|PR.DS-4,CSF|PR.PT-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-4,LEVEL|1A,NESA|T3.3.1,NESA|T3.6.2,QCSC-v1|8.2.1,QCSC-v1|13.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-log-maxbackup=@AUDIT_LOG_MAXBACKUP@([\\\\s]|$)"
    },
    "custom_item_56": {
        "system": "Linux",
        "description": "1.2.21 Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate",
        "info": "Rotate log files on reaching 100 MB or as appropriate.\n\nRationale:\n\nKubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --audit-log-maxsize parameter to an appropriate size in MB. For example, to set it as 100 MB:\n\n--audit-log-maxsize=100\n\nDefault Value:\n\nBy default, auditing is not enabled.",
        "reference": "800-53|AU-4,800-53r5|AU-4,CSCv7|6.4,CSCv8|8.3,CSF|PR.DS-4,CSF|PR.PT-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-4,LEVEL|1A,NESA|T3.3.1,NESA|T3.6.2,QCSC-v1|8.2.1,QCSC-v1|13.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-log-maxsize=@AUDIT_LOG_MAXSIZE@([\\\\s]|$)"
    },
    "custom_item_57": {
        "system": "Linux",
        "description": "1.2.22 Ensure that the --request-timeout argument is set as appropriate",
        "info": "Set global request timeout for API server requests as appropriate.\n\nRationale:\n\nSetting global request timeout allows extending the API server request timeout limit to a duration appropriate to the user's connection speed. By default, it is set to 60 seconds which might be problematic on slower connections making cluster resources inaccessible once the data volume for requests exceeds what can be transmitted in 60 seconds. But, setting this timeout limit to be too large can exhaust the API server resources making it prone to Denial-of-Service attack. Hence, it is recommended to set this limit as appropriate and change the default limit of 60 seconds only if needed.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml and set the below parameter as appropriate and if needed. For example,\n\n--request-timeout=300s\n\nDefault Value:\n\nBy default, --request-timeout is set to 60 seconds.",
        "reference": "800-171|3.4.2,800-53|CM-6,800-53r5|CM-6,CSCv7|5.1,CSCv8|4,CSF|PR.IP-1,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,LEVEL|1M,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "(--request-timeout=@REQUEST_TIMEOUT@([\\\\s]|$)|^((?!--request-timeout).)*$)"
    },
    "custom_item_58": {
        "system": "Linux",
        "description": "1.2.23 Ensure that the --service-account-lookup argument is set to true",
        "info": "Validate service account before validating token.\n\nRationale:\n\nIf --service-account-lookup is not enabled, the apiserver only verifies that the authentication token is valid, and does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.\n\nImpact:\n\nNone",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n--service-account-lookup=true\n\nAlternatively, you can delete the --service-account-lookup parameter from this file so that the default takes effect.\n\nDefault Value:\n\nBy default, --service-account-lookup argument is set to true.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|16,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--service-account-lookup=true"
    },
    "custom_item_59": {
        "system": "Linux",
        "description": "1.2.24 Ensure that the --service-account-key-file argument is set as appropriate",
        "info": "Explicitly set a service account public key file for service accounts on the apiserver.\n\nRationale:\n\nBy default, if no --service-account-key-file is specified to the apiserver, it uses the private key from the TLS serving certificate to verify service account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with --service-account-key-file.\n\nImpact:\n\nThe corresponding private key must be provided to the controller manager. You would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the --service-account-key-file parameter to the public key file for service accounts:\n\n--service-account-key-file=Default Value:\n\nBy default, --service-account-key-file argument is not set.",
        "reference": "800-171|3.5.2,800-53|IA-5(1),800-53r5|IA-5(1),CSCv7|4.4,CSCv8|5.2,CSF|PR.AC-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),ITSG-33|IA-5(1),LEVEL|1A,NESA|T5.2.3,QCSC-v1|5.2.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--service-account-key-file=@SERVICE_ACCOUNT_KEY_FILE@([\\\\s]|$)"
    },
    "custom_item_60": {
        "system": "Linux",
        "description": "1.2.25 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate - certfile",
        "info": "etcd should be configured to make use of TLS encryption for client connections.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a client certificate and key.\n\nImpact:\n\nTLS and client certificate authentication must be configured for etcd.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate and key file parameters.\n\n--etcd-certfile=--etcd-keyfile=Default Value:\n\nBy default, --etcd-certfile and --etcd-keyfile arguments are not set",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--etcd-certfile=@ETCD_CERTFILE@([\\\\s]|$)"
    },
    "custom_item_61": {
        "system": "Linux",
        "description": "1.2.25 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate - keyfile",
        "info": "etcd should be configured to make use of TLS encryption for client connections.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a client certificate and key.\n\nImpact:\n\nTLS and client certificate authentication must be configured for etcd.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate and key file parameters.\n\n--etcd-certfile=--etcd-keyfile=Default Value:\n\nBy default, --etcd-certfile and --etcd-keyfile arguments are not set",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--etcd-keyfile=@ETCD_KEYFILE@([\\\\s]|$)"
    },
    "custom_item_62": {
        "system": "Linux",
        "description": "1.2.26 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate - cert",
        "info": "Setup TLS connection on the API server.\n\nRationale:\n\nAPI server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic.\n\nImpact:\n\nTLS and client certificate authentication must be configured for your Kubernetes cluster deployment.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the TLS certificate and private key file parameters.\n\n--tls-cert-file=--tls-private-key-file=Default Value:\n\nBy default, --tls-cert-file and --tls-private-key-file arguments are not set.",
        "reference": "800-171|3.1.13,800-171|3.5.2,800-171|3.13.8,800-53|AC-17(2),800-53|IA-5,800-53|IA-5(1),800-53|SC-8,800-53|SC-8(1),800-53r5|AC-17(2),800-53r5|IA-5,800-53r5|IA-5(1),800-53r5|SC-8,800-53r5|SC-8(1),CN-L3|7.1.2.7(g),CN-L3|7.1.3.1(d),CN-L3|8.1.2.2(a),CN-L3|8.1.2.2(b),CN-L3|8.1.4.1(c),CN-L3|8.1.4.7(a),CN-L3|8.1.4.8(a),CN-L3|8.2.4.5(c),CN-L3|8.2.4.5(d),CN-L3|8.5.2.2,CSCv7|14.4,CSCv8|3.10,CSF|PR.AC-1,CSF|PR.AC-3,CSF|PR.DS-2,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),HIPAA|164.312(e)(1),HIPAA|164.312(e)(2)(i),ISO/IEC-27001|A.6.2.2,ISO/IEC-27001|A.10.1.1,ISO/IEC-27001|A.13.2.3,ITSG-33|AC-17(2),ITSG-33|IA-5,ITSG-33|IA-5(1),ITSG-33|SC-8,ITSG-33|SC-8a.,ITSG-33|SC-8(1),LEVEL|1A,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.2,NESA|T5.2.3,NESA|T5.4.2,NESA|T7.3.3,NESA|T7.4.1,NIAv2|AM37,NIAv2|IE8,NIAv2|IE9,NIAv2|IE12,NIAv2|NS5d,NIAv2|NS6b,NIAv2|NS29,NIAv2|SS24,PCI-DSSv3.2.1|2.3,PCI-DSSv3.2.1|4.1,PCI-DSSv4.0|2.2.7,PCI-DSSv4.0|4.2.1,QCSC-v1|3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|2.1,SWIFT-CSCv1|2.6,SWIFT-CSCv1|4.1,TBA-FIISB|29.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--tls-cert-file=@TLS_CERT_FILE@([\\\\s]|$)"
    },
    "custom_item_63": {
        "system": "Linux",
        "description": "1.2.26 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate - key",
        "info": "Setup TLS connection on the API server.\n\nRationale:\n\nAPI server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic.\n\nImpact:\n\nTLS and client certificate authentication must be configured for your Kubernetes cluster deployment.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the TLS certificate and private key file parameters.\n\n--tls-cert-file=--tls-private-key-file=Default Value:\n\nBy default, --tls-cert-file and --tls-private-key-file arguments are not set.",
        "reference": "800-171|3.1.13,800-171|3.5.2,800-171|3.13.8,800-53|AC-17(2),800-53|IA-5,800-53|IA-5(1),800-53|SC-8,800-53|SC-8(1),800-53r5|AC-17(2),800-53r5|IA-5,800-53r5|IA-5(1),800-53r5|SC-8,800-53r5|SC-8(1),CN-L3|7.1.2.7(g),CN-L3|7.1.3.1(d),CN-L3|8.1.2.2(a),CN-L3|8.1.2.2(b),CN-L3|8.1.4.1(c),CN-L3|8.1.4.7(a),CN-L3|8.1.4.8(a),CN-L3|8.2.4.5(c),CN-L3|8.2.4.5(d),CN-L3|8.5.2.2,CSCv7|14.4,CSCv8|3.10,CSF|PR.AC-1,CSF|PR.AC-3,CSF|PR.DS-2,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),HIPAA|164.312(e)(1),HIPAA|164.312(e)(2)(i),ISO/IEC-27001|A.6.2.2,ISO/IEC-27001|A.10.1.1,ISO/IEC-27001|A.13.2.3,ITSG-33|AC-17(2),ITSG-33|IA-5,ITSG-33|IA-5(1),ITSG-33|SC-8,ITSG-33|SC-8a.,ITSG-33|SC-8(1),LEVEL|1A,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.2,NESA|T5.2.3,NESA|T5.4.2,NESA|T7.3.3,NESA|T7.4.1,NIAv2|AM37,NIAv2|IE8,NIAv2|IE9,NIAv2|IE12,NIAv2|NS5d,NIAv2|NS6b,NIAv2|NS29,NIAv2|SS24,PCI-DSSv3.2.1|2.3,PCI-DSSv3.2.1|4.1,PCI-DSSv4.0|2.2.7,PCI-DSSv4.0|4.2.1,QCSC-v1|3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|2.1,SWIFT-CSCv1|2.6,SWIFT-CSCv1|4.1,TBA-FIISB|29.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--tls-private-key-file=@TLS_PRIVATE_KEY_FILE@([\\\\s]|$)"
    },
    "custom_item_64": {
        "system": "Linux",
        "description": "1.2.27 Ensure that the --client-ca-file argument is set as appropriate",
        "info": "Setup TLS connection on the API server.\n\nRationale:\n\nAPI server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic. If --client-ca-file argument is set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.\n\nImpact:\n\nTLS and client certificate authentication must be configured for your Kubernetes cluster deployment.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the client certificate authority file.\n\n--client-ca-file=Default Value:\n\nBy default, --client-ca-file argument is not set.",
        "reference": "800-171|3.1.13,800-171|3.5.2,800-171|3.13.8,800-53|AC-17(2),800-53|IA-5,800-53|IA-5(1),800-53|SC-8,800-53|SC-8(1),800-53r5|AC-17(2),800-53r5|IA-5,800-53r5|IA-5(1),800-53r5|SC-8,800-53r5|SC-8(1),CN-L3|7.1.2.7(g),CN-L3|7.1.3.1(d),CN-L3|8.1.2.2(a),CN-L3|8.1.2.2(b),CN-L3|8.1.4.1(c),CN-L3|8.1.4.7(a),CN-L3|8.1.4.8(a),CN-L3|8.2.4.5(c),CN-L3|8.2.4.5(d),CN-L3|8.5.2.2,CSCv7|14.4,CSCv8|3.10,CSF|PR.AC-1,CSF|PR.AC-3,CSF|PR.DS-2,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),HIPAA|164.312(e)(1),HIPAA|164.312(e)(2)(i),ISO/IEC-27001|A.6.2.2,ISO/IEC-27001|A.10.1.1,ISO/IEC-27001|A.13.2.3,ITSG-33|AC-17(2),ITSG-33|IA-5,ITSG-33|IA-5(1),ITSG-33|SC-8,ITSG-33|SC-8a.,ITSG-33|SC-8(1),LEVEL|1A,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.2,NESA|T5.2.3,NESA|T5.4.2,NESA|T7.3.3,NESA|T7.4.1,NIAv2|AM37,NIAv2|IE8,NIAv2|IE9,NIAv2|IE12,NIAv2|NS5d,NIAv2|NS6b,NIAv2|NS29,NIAv2|SS24,PCI-DSSv3.2.1|2.3,PCI-DSSv3.2.1|4.1,PCI-DSSv4.0|2.2.7,PCI-DSSv4.0|4.2.1,QCSC-v1|3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|2.1,SWIFT-CSCv1|2.6,SWIFT-CSCv1|4.1,TBA-FIISB|29.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--client-ca-file=@CLIENT_CA_FILE@([\\\\s]|$)"
    },
    "custom_item_65": {
        "system": "Linux",
        "description": "1.2.28 Ensure that the --etcd-cafile argument is set as appropriate",
        "info": "etcd should be configured to make use of TLS encryption for client connections.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using an SSL Certificate Authority file.\n\nImpact:\n\nTLS and client certificate authentication must be configured for etcd.",
        "solution": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the etcd certificate authority file parameter.\n\n--etcd-cafile=Default Value:\n\nBy default, --etcd-cafile is not set.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--etcd-cafile=@ETCD_CAFILE@([\\\\s]|$)"
    },
    "custom_item_66": {
        "system": "Linux",
        "description": "1.2.29 Ensure that the --encryption-provider-config argument is set as appropriate",
        "info": "Encrypt etcd key-value store.\n\nRationale:\n\netcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted at rest to avoid any disclosures.\n\nImpact:\n\nNone",
        "solution": "Follow the Kubernetes documentation and configure a EncryptionConfig file. Then, edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the master node and set the --encryption-provider-config parameter to the path of that file:\n\n--encryption-provider-config=Default Value:\n\nBy default, --encryption-provider-config is not set.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1M,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--encryption-provider-config=@ENCRYPTION_PROVIDER_CONFIG@([\\\\s]|$)"
    },
    "custom_item_67": {
        "system": "Linux",
        "description": "1.2.30 Ensure that encryption providers are appropriately configured",
        "info": "Where etcd encryption is used, appropriate providers should be configured.\n\nRationale:\n\nWhere etcd encryption is used, it is important to ensure that the appropriate set of encryption providers is used. Currently, the aescbc, kms and secretbox are likely to be appropriate options.\n\nImpact:\n\nNone",
        "solution": "Follow the Kubernetes documentation and configure a EncryptionConfig file. In this file, choose aescbc, kms or secretbox as the encryption provider.\n\nDefault Value:\n\nBy default, no encryption provider is set.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1M,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@ENCRYPTION_PROVIDER_CONFIG@",
        "regex": "^[\\\\s]*-[\\\\s]*aesgcm[\\\\s]*:",
        "expect": "^[\\\\s]*-[\\\\s]*aesgcm[\\\\s]*:"
    },
    "custom_item_68": {
        "system": "Linux",
        "description": "1.2.31 Ensure that the API Server only makes use of Strong Cryptographic Ciphers",
        "info": "Ensure that the API server is configured to only use strong cryptographic ciphers.\n\nRationale:\n\nTLS ciphers have had a number of known vulnerabilities and weaknesses, which can reduce the protection provided by them. By default Kubernetes supports a number of TLS ciphersuites including some that have security concerns, weakening the protection provided.\n\nImpact:\n\nAPI server clients that cannot support modern cryptographic ciphers will not be able to make connections to the API server.",
        "solution": "Edit the API server pod specification file /etc/kubernetes/manifests/kube-apiserver.yaml on the Control Plane node and set the below parameter.\n\n--tls-cipher-suites=TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384.\n\nDefault Value:\n\nBy default the Kubernetes API server supports a wide range of TLS ciphers",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|5.1,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1M,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--tls-cipher-suites=((TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256|TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256|TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305|TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384|TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305|TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384|TLS_RSA_WITH_AES_256_GCM_SHA384|TLS_RSA_WITH_AES_128_GCM_SHA256)[,]?)+([\\\\s]|$)"
    },
    "custom_item_69": {
        "description": "Check if Controller Manager is running",
        "name": "kube-controller"
    },
    "custom_item_70": {
        "system": "Linux",
        "description": "1.3.1 Ensure that the --terminated-pod-gc-threshold argument is set as appropriate",
        "info": "Activate garbage collector on pod termination, as appropriate.\n\nRationale:\n\nGarbage collection is important to ensure sufficient resource availability and avoiding degraded performance and availability. In the worst case, the system might crash or just be unusable for a long period of time. The current setting for garbage collection is 12,500 terminated pods which might be too high for your system to sustain. Based on your system resources and tests, choose an appropriate threshold value to activate garbage collection.\n\nImpact:\n\nNone",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node and set the --terminated-pod-gc-threshold to an appropriate threshold, for example:\n\n--terminated-pod-gc-threshold=10\n\nDefault Value:\n\nBy default, --terminated-pod-gc-threshold is set to 12500.",
        "reference": "800-53|SI-16,800-53r5|SI-16,CSCv7|5.1,CSCv8|10.5,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|SI-16,LEVEL|1M",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--terminated-pod-gc-threshold=@TERMINATED_POD_GC_THRESHOLD@([\\\\s]|$)"
    },
    "custom_item_71": {
        "system": "Linux",
        "description": "1.3.2 Ensure that the --profiling argument is set to false",
        "info": "Disable profiling, if not needed.\n\nRationale:\n\nProfiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\n\nImpact:\n\nProfiling information would not be available.",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node and set the below parameter.\n\n--profiling=false\n\nDefault Value:\n\nBy default, profiling is enabled.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|9.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--profiling=false"
    },
    "custom_item_72": {
        "system": "Linux",
        "description": "1.3.3 Ensure that the --use-service-account-credentials argument is set to true",
        "info": "Use individual service account credentials for each controller.\n\nRationale:\n\nThe controller manager creates a service account per controller in the kube-system namespace, generates a credential for it, and builds a dedicated API client with that service account credential for each controller loop to use. Setting the --use-service-account-credentials to true runs each control loop within the controller manager using a separate service account credential. When used in combination with RBAC, this ensures that the control loops run with the minimum permissions required to perform their intended tasks.\n\nImpact:\n\nWhatever authorizer is configured for the cluster, it must grant sufficient permissions to the service accounts to perform their intended tasks. When using the RBAC authorizer, those roles are created and bound to the appropriate service accounts in the kube-system namespace automatically with default roles and rolebindings that are auto-reconciled on startup.\n\nIf using other authorization methods (ABAC, Webhook, etc), the cluster deployer is responsible for granting appropriate permissions to the service accounts (the required permissions can be seen by inspecting the controller-roles.yaml and controller-role-bindings.yaml files for the RBAC roles.",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node to set the below parameter.\n\n--use-service-account-credentials=true\n\nDefault Value:\n\nBy default, --use-service-account-credentials is set to false.",
        "reference": "800-171|3.1.1,800-171|3.1.5,800-171|3.3.8,800-171|3.3.9,800-171|3.5.2,800-53|AC-2,800-53|AC-3,800-53|AC-6,800-53|AC-6(1),800-53|AC-6(7),800-53|AU-9(4),800-53|IA-5(1),800-53r5|AC-2,800-53r5|AC-3,800-53r5|AC-6,800-53r5|AC-6(1),800-53r5|AC-6(7),800-53r5|AU-9(4),800-53r5|IA-5(1),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(d),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.3(d),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|4.4,CSCv8|5.2,CSCv8|6.8,CSF|DE.CM-1,CSF|DE.CM-3,CSF|PR.AC-1,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(b),HIPAA|164.312(d),ISO/IEC-27001|A.9.2.1,ISO/IEC-27001|A.9.2.5,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.4,ISO/IEC-27001|A.9.4.5,ISO/IEC-27001|A.12.4.2,ITSG-33|AC-2,ITSG-33|AC-3,ITSG-33|AC-6,ITSG-33|AC-6(1),ITSG-33|AU-9(4),ITSG-33|AU-9(4)(a),ITSG-33|AU-9(4)(b),ITSG-33|IA-5(1),LEVEL|1A,NESA|M1.1.3,NESA|M1.2.2,NESA|M5.2.3,NESA|M5.5.2,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.2.3,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|AM28,NIAv2|AM31,NIAv2|GS3,NIAv2|GS4,NIAv2|GS8c,NIAv2|NS5j,NIAv2|SM5,NIAv2|SM6,NIAv2|SS13c,NIAv2|SS14e,NIAv2|SS15c,NIAv2|SS29,NIAv2|VL3b,PCI-DSSv3.2.1|7.1.2,PCI-DSSv3.2.1|10.5,PCI-DSSv3.2.1|10.5.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,PCI-DSSv4.0|10.3.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|13.2,QCSC-v1|15.2,SWIFT-CSCv1|4.1,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--use-service-account-credentials=true"
    },
    "custom_item_73": {
        "system": "Linux",
        "description": "1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate",
        "info": "Explicitly set a service account private key file for service accounts on the controller manager.\n\nRationale:\n\nTo ensure that keys for service account tokens can be rotated as needed, a separate public/private key pair should be used for signing service account tokens. The private key should be specified to the controller manager with --service-account-private-key-file as appropriate.\n\nImpact:\n\nYou would need to securely maintain the key file and rotate the keys based on your organization's key rotation policy.",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node and set the --service-account-private-key-file parameter to the private key file for service accounts.\n\n--service-account-private-key-file=Default Value:\n\nBy default, --service-account-private-key-file it not set.",
        "reference": "800-171|3.5.2,800-53|IA-5(1),800-53r5|IA-5(1),CSCv7|4.4,CSCv8|5.2,CSF|PR.AC-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),ITSG-33|IA-5(1),LEVEL|1A,NESA|T5.2.3,QCSC-v1|5.2.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--service-account-private-key-file=@SERVICE_ACCOUNT_PRIVATE_KEY_FILE@([\\\\s]|$)"
    },
    "custom_item_74": {
        "system": "Linux",
        "description": "1.3.5 Ensure that the --root-ca-file argument is set as appropriate",
        "info": "Allow pods to verify the API server's serving certificate before establishing connections.\n\nRationale:\n\nProcesses running within pods that need to contact the API server must verify the API server's serving certificate. Failing to do so could be a subject to man-in-the-middle attacks.\n\nProviding the root certificate for the API server's serving certificate to the controller manager with the --root-ca-file argument allows the controller manager to inject the trusted bundle into pods so that they can verify TLS connections to the API server.\n\nImpact:\n\nYou need to setup and maintain root certificate authority file.",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node and set the --root-ca-file parameter to the certificate bundle file'.\n\n--root-ca-file=Default Value:\n\nBy default, --root-ca-file is not set.",
        "reference": "800-171|3.1.13,800-171|3.5.2,800-171|3.13.8,800-53|AC-17(2),800-53|IA-5,800-53|IA-5(1),800-53|SC-8,800-53|SC-8(1),800-53r5|AC-17(2),800-53r5|IA-5,800-53r5|IA-5(1),800-53r5|SC-8,800-53r5|SC-8(1),CN-L3|7.1.2.7(g),CN-L3|7.1.3.1(d),CN-L3|8.1.2.2(a),CN-L3|8.1.2.2(b),CN-L3|8.1.4.1(c),CN-L3|8.1.4.7(a),CN-L3|8.1.4.8(a),CN-L3|8.2.4.5(c),CN-L3|8.2.4.5(d),CN-L3|8.5.2.2,CSCv7|14.4,CSCv8|3.10,CSF|PR.AC-1,CSF|PR.AC-3,CSF|PR.DS-2,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),HIPAA|164.312(e)(1),HIPAA|164.312(e)(2)(i),ISO/IEC-27001|A.6.2.2,ISO/IEC-27001|A.10.1.1,ISO/IEC-27001|A.13.2.3,ITSG-33|AC-17(2),ITSG-33|IA-5,ITSG-33|IA-5(1),ITSG-33|SC-8,ITSG-33|SC-8a.,ITSG-33|SC-8(1),LEVEL|1A,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.2,NESA|T5.2.3,NESA|T5.4.2,NESA|T7.3.3,NESA|T7.4.1,NIAv2|AM37,NIAv2|IE8,NIAv2|IE9,NIAv2|IE12,NIAv2|NS5d,NIAv2|NS6b,NIAv2|NS29,NIAv2|SS24,PCI-DSSv3.2.1|2.3,PCI-DSSv3.2.1|4.1,PCI-DSSv4.0|2.2.7,PCI-DSSv4.0|4.2.1,QCSC-v1|3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|2.1,SWIFT-CSCv1|2.6,SWIFT-CSCv1|4.1,TBA-FIISB|29.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--root-ca-file=@ROOT_CA_FILE@([\\\\s]|$)"
    },
    "custom_item_75": {
        "system": "Linux",
        "description": "1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1",
        "info": "Do not bind the Controller Manager service to non-loopback insecure addresses.\n\nRationale:\n\nThe Controller Manager API service which runs on port 10252/TCP by default is used for health and metrics information and is available without authentication or encryption. As such it should only be bound to a localhost interface, to minimize the cluster's attack surface\n\nImpact:\n\nNone",
        "solution": "Edit the Controller Manager pod specification file /etc/kubernetes/manifests/kube-controller-manager.yaml on the Control Plane node and ensure the correct value for the --bind-address parameter\n\nDefault Value:\n\nBy default, the --bind-address parameter is set to 0.0.0.0",
        "reference": "800-171|3.1.16,800-171|3.13.15,800-53|AC-18,800-53|SC-23,800-53r5|AC-18,800-53r5|SC-23,CSCv7|9.2,CSCv8|12.6,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ITSG-33|AC-18,ITSG-33|SC-23,ITSG-33|SC-23a.,LEVEL|1A,NESA|T4.5.1,QCSC-v1|5.2.1,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-controller-manager | grep -v grep",
        "expect": "--bind-address=127.0.0.1([\\\\s]|$)"
    },
    "custom_item_76": {
        "description": "Check if Scheduler is running",
        "name": "kube-scheduler"
    },
    "custom_item_77": {
        "system": "Linux",
        "description": "1.4.1 Ensure that the --profiling argument is set to false",
        "info": "Disable profiling, if not needed.\n\nRationale:\n\nProfiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\n\nImpact:\n\nProfiling information would not be available.",
        "solution": "Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube-scheduler.yaml file on the Control Plane node and set the below parameter.\n\n--profiling=false\n\nDefault Value:\n\nBy default, profiling is enabled.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|9.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-scheduler | grep -v grep",
        "expect": "--profiling=false"
    },
    "custom_item_78": {
        "system": "Linux",
        "description": "1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1",
        "info": "Do not bind the scheduler service to non-loopback insecure addresses.\n\nRationale:\n\nThe Scheduler API service which runs on port 10251/TCP by default is used for health and metrics information and is available without authentication or encryption. As such it should only be bound to a localhost interface, to minimize the cluster's attack surface\n\nImpact:\n\nNone",
        "solution": "Edit the Scheduler pod specification file /etc/kubernetes/manifests/kube-scheduler.yaml on the Control Plane node and ensure the correct value for the --bind-address parameter\n\nDefault Value:\n\nBy default, the --bind-address parameter is set to 0.0.0.0",
        "reference": "800-171|3.1.16,800-171|3.13.15,800-53|AC-18,800-53|SC-23,800-53r5|AC-18,800-53r5|SC-23,CSCv7|9.2,CSCv8|12.6,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ITSG-33|AC-18,ITSG-33|SC-23,ITSG-33|SC-23a.,LEVEL|1A,NESA|T4.5.1,QCSC-v1|5.2.1,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-scheduler | grep -v grep",
        "expect": "--bind-address=127.0.0.1([\\\\s]|$)"
    },
    "custom_item_79": {
        "description": "Check if etcd is running",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "etcd[2]?[\\\\s]"
    },
    "custom_item_80": {
        "system": "Linux",
        "description": "2.1 Ensure that the --cert-file and --key-file arguments are set as appropriate - cert",
        "info": "Configure TLS encryption for the etcd service.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit.\n\nImpact:\n\nClient connections only over TLS would be served.",
        "solution": "Follow the etcd service documentation and configure TLS encryption.\nThen, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.\n\n--cert-file=--key-file=Default Value:\n\nBy default, TLS encryption is not set.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.4,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--cert-file=@CERT_FILE@([\\\\s]|$)"
    },
    "custom_item_81": {
        "system": "Linux",
        "description": "2.1 Ensure that the --cert-file and --key-file arguments are set as appropriate - key",
        "info": "Configure TLS encryption for the etcd service.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit.\n\nImpact:\n\nClient connections only over TLS would be served.",
        "solution": "Follow the etcd service documentation and configure TLS encryption.\nThen, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.\n\n--cert-file=--key-file=Default Value:\n\nBy default, TLS encryption is not set.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.4,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--key-file=@KEY_FILE@([\\\\s]|$)"
    },
    "custom_item_82": {
        "system": "Linux",
        "description": "2.2 Ensure that the --client-cert-auth argument is set to true",
        "info": "Enable client authentication on etcd service.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.\n\nImpact:\n\nAll clients attempting to access the etcd server will require a valid client certificate.",
        "solution": "Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter.\n\n--client-cert-auth='true'\n\nDefault Value:\n\nBy default, the etcd service can be queried by unauthenticated clients.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.8,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--client-cert-auth=true"
    },
    "custom_item_83": {
        "system": "Linux",
        "description": "2.3 Ensure that the --auto-tls argument is not set to true",
        "info": "Do not use self-signed certificates for TLS.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.\n\nImpact:\n\nClients will not be able to use self-signed certificates for TLS.",
        "solution": "Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and either remove the --auto-tls parameter or set it to false.\n\n--auto-tls=false\n\nDefault Value:\n\nBy default, --auto-tls is set to false.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.4,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "^((?!--auto-tls=true).)*$"
    },
    "custom_item_84": {
        "system": "Linux",
        "description": "2.4 Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate - cert",
        "info": "etcd should be configured to make use of TLS encryption for peer connections.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit and also amongst peers in the etcd clusters.\n\nImpact:\n\netcd cluster peers would need to set up TLS for their communication.",
        "solution": "Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.\nThen, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.\n\n--peer-client-file=--peer-key-file=Default Value:\n\nNote: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\nBy default, peer communication over TLS is not configured.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.4,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--peer-cert-file=@PEER_CERT_FILE@([\\\\s]|$)"
    },
    "custom_item_85": {
        "system": "Linux",
        "description": "2.4 Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate - key",
        "info": "etcd should be configured to make use of TLS encryption for peer connections.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit and also amongst peers in the etcd clusters.\n\nImpact:\n\netcd cluster peers would need to set up TLS for their communication.",
        "solution": "Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.\nThen, edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameters.\n\n--peer-client-file=--peer-key-file=Default Value:\n\nNote: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\nBy default, peer communication over TLS is not configured.",
        "reference": "800-171|3.5.2,800-171|3.13.16,800-53|IA-5(1),800-53|SC-28,800-53|SC-28(1),800-53r5|IA-5(1),800-53r5|SC-28,800-53r5|SC-28(1),CN-L3|8.1.4.7(b),CN-L3|8.1.4.8(b),CSCv7|14.4,CSCv8|3.11,CSF|PR.AC-1,CSF|PR.DS-1,GDPR|32.1.a,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(a)(2)(iv),HIPAA|164.312(d),HIPAA|164.312(e)(2)(ii),ITSG-33|IA-5(1),ITSG-33|SC-28,ITSG-33|SC-28a.,ITSG-33|SC-28(1),LEVEL|1A,NESA|T5.2.3,PCI-DSSv3.2.1|3.4,PCI-DSSv4.0|3.3.2,PCI-DSSv4.0|3.5.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1,TBA-FIISB|28.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--peer-key-file=@PEER_KEY_FILE@([\\\\s]|$)"
    },
    "custom_item_86": {
        "system": "Linux",
        "description": "2.5 Ensure that the --peer-client-cert-auth argument is set to true",
        "info": "etcd should be configured for peer authentication.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster.\n\nImpact:\n\nAll peers attempting to communicate with the etcd server will require a valid client certificate for authentication.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and set the below parameter.\n\n--peer-client-cert-auth=true\n\nDefault Value:\n\nNote: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\nBy default, --peer-client-cert-auth argument is set to false.",
        "reference": "800-171|3.1.1,800-171|3.1.4,800-171|3.1.5,800-171|3.8.1,800-171|3.8.2,800-171|3.8.3,800-53|AC-3,800-53|AC-5,800-53|AC-6,800-53|MP-2,800-53r5|AC-3,800-53r5|AC-5,800-53r5|AC-6,800-53r5|MP-2,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|14.6,CSCv8|3.3,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-2,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.6.1.2,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.5,ITSG-33|AC-3,ITSG-33|AC-5,ITSG-33|AC-6,ITSG-33|MP-2,ITSG-33|MP-2a.,LEVEL|1A,NESA|T1.3.2,NESA|T1.3.3,NESA|T1.4.1,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,NIAv2|SS29,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "--peer-client-cert-auth=true"
    },
    "custom_item_87": {
        "system": "Linux",
        "description": "2.6 Ensure that the --peer-auto-tls argument is not set to true",
        "info": "Do not use automatically generated self-signed certificates for TLS connections between peers.\n\nRationale:\n\netcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster. Hence, do not use self-signed certificates for authentication.\n\nImpact:\n\nAll peers attempting to communicate with the etcd server will require a valid client certificate for authentication.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Edit the etcd pod specification file /etc/kubernetes/manifests/etcd.yaml on the master node and either remove the --peer-auto-tls parameter or set it to false.\n\n--peer-auto-tls=false\n\nDefault Value:\n\nNote: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\n\nBy default, --peer-auto-tls argument is set to false.",
        "reference": "800-171|3.5.2,800-53|IA-5(1),800-53r5|IA-5(1),CSCv7|4.4,CSCv8|5.2,CSF|PR.AC-1,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(2)(i),HIPAA|164.312(d),ITSG-33|IA-5(1),LEVEL|1A,NESA|T5.2.3,QCSC-v1|5.2.2,QCSC-v1|13.2,SWIFT-CSCv1|4.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | egrep '/etcd[2]?([[:space:]]|$)' | grep -v grep",
        "expect": "^((?!--peer-auto-tls=true).)*$"
    },
    "custom_item_88": {
        "system": "Linux",
        "description": "3.1.1 Client certificate authentication should not be used for users",
        "info": "Kubernetes provides the option to use client certificates for user authentication. However as there is no way to revoke these certificates when a user leaves an organization or loses their credential, they are not suitable for this purpose.\n\nIt is not possible to fully disable client certificate use within a cluster as it is used for component to component authentication.\n\nRationale:\n\nWith any authentication mechanism the ability to revoke credentials if they are compromised or no longer required, is a key control. Kubernetes client certificate authentication does not allow for this due to a lack of support for certificate revocation.\n\nImpact:\n\nExternal mechanisms for authentication generally require additional software to be deployed.",
        "solution": "Alternative mechanisms provided by Kubernetes such as the use of OIDC should be implemented in place of client certificates.\n\nDefault Value:\n\nClient certificate authentication is enabled by default.\n\nAdditional Information:\n\nThe lack of certificate revocation was flagged up as a high risk issue in the recent Kubernetes security audit. Without this feature, client certificate authentication is not suitable for end users.",
        "reference": "800-171|3.1.1,800-53|AC-1,800-53|AC-2,800-53|AC-2(1),800-53r5|AC-1,800-53r5|AC-2,800-53r5|AC-2(1),CN-L3|7.1.3.2(d),CN-L3|8.1.4.2(e),CN-L3|8.1.10.6(c),CSCv7|16.7,CSCv8|6.2,CSF|DE.CM-1,CSF|DE.CM-3,CSF|ID.GV-1,CSF|ID.GV-3,CSF|PR.AC-1,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.1.1,ISO/IEC-27001|A.9.2.1,ITSG-33|AC-1,ITSG-33|AC-2,ITSG-33|AC-2(1),LEVEL|1M,NESA|M1.2.2,NIAv2|AM28,NIAv2|AM29,NIAv2|AM30,NIAv2|NS5j,NIAv2|SS14e,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|8.2.1,QCSC-v1|13.2,QCSC-v1|15.2",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep | grep -- '--client-ca-file' | awk '{print} END {if (NR == 0) print \"--client-ca-file does not exist\"}'",
        "expect": "--client-ca-file does not exist"
    },
    "custom_item_89": {
        "description": "Check if API Server is running",
        "name": "kube-apiserver"
    },
    "custom_item_90": {
        "description": "3.2.1 Ensure that a minimal audit policy is created",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-policy-file=@AUDIT_POLICY_FILE@([\\\\s]|$)"
    },
    "custom_item_91": {
        "system": "Linux",
        "description": "3.2.1 Ensure that a minimal audit policy is created",
        "info": "Kubernetes can audit the details of requests made to the API server. The --audit-policy-file flag must be set for this logging to be enabled.\n\nRationale:\n\nLogging is an important detective control for all systems, to detect potential unauthorized access.\n\nImpact:\n\nAudit logs will be created on the master nodes, which will consume disk space. Care should be taken to avoid generating too large volumes of log information as this could impact the available of the cluster nodes.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Create an audit policy file for your cluster.\n\nDefault Value:\n\nUnless the --audit-policy-file flag is specified, no auditing will be carried out.",
        "reference": "800-171|3.3.1,800-171|3.3.2,800-171|3.3.6,800-53|AU-2,800-53|AU-7,800-53|AU-12,800-53r5|AU-2,800-53r5|AU-7,800-53r5|AU-12,CN-L3|7.1.2.3(c),CN-L3|8.1.4.3(a),CSCv7|6.2,CSCv8|8.2,CSF|DE.CM-1,CSF|DE.CM-3,CSF|DE.CM-7,CSF|PR.PT-1,CSF|RS.AN-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-2,ITSG-33|AU-7,ITSG-33|AU-12,LEVEL|1M,NESA|M1.2.2,NESA|M5.5.1,NIAv2|AM7,NIAv2|AM11a,NIAv2|AM11b,NIAv2|AM11c,NIAv2|AM11d,NIAv2|AM11e,NIAv2|SS30,NIAv2|VL8,PCI-DSSv3.2.1|10.1,QCSC-v1|3.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|10.2.1,QCSC-v1|11.2,QCSC-v1|13.2,SWIFT-CSCv1|6.4",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "file": "@AUDIT_POLICY_FILE@",
        "regex": ".*",
        "expect": "$MANUAL_REVIEW^"
    },
    "custom_item_92": {
        "system": "Linux",
        "description": "3.2.1 Ensure that a minimal audit policy is created",
        "info": "Kubernetes can audit the details of requests made to the API server. The --audit-policy-file flag must be set for this logging to be enabled.\n\nRationale:\n\nLogging is an important detective control for all systems, to detect potential unauthorized access.\n\nImpact:\n\nAudit logs will be created on the master nodes, which will consume disk space. Care should be taken to avoid generating too large volumes of log information as this could impact the available of the cluster nodes.",
        "solution": "Create an audit policy file for your cluster.\n\nDefault Value:\n\nUnless the --audit-policy-file flag is specified, no auditing will be carried out.",
        "reference": "800-171|3.3.1,800-171|3.3.2,800-171|3.3.6,800-53|AU-2,800-53|AU-7,800-53|AU-12,800-53r5|AU-2,800-53r5|AU-7,800-53r5|AU-12,CN-L3|7.1.2.3(c),CN-L3|8.1.4.3(a),CSCv7|6.2,CSCv8|8.2,CSF|DE.CM-1,CSF|DE.CM-3,CSF|DE.CM-7,CSF|PR.PT-1,CSF|RS.AN-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(b),ITSG-33|AU-2,ITSG-33|AU-7,ITSG-33|AU-12,LEVEL|1M,NESA|M1.2.2,NESA|M5.5.1,NIAv2|AM7,NIAv2|AM11a,NIAv2|AM11b,NIAv2|AM11c,NIAv2|AM11d,NIAv2|AM11e,NIAv2|SS30,NIAv2|VL8,PCI-DSSv3.2.1|10.1,QCSC-v1|3.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|10.2.1,QCSC-v1|11.2,QCSC-v1|13.2,SWIFT-CSCv1|6.4",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "ps -ef | grep kube-apiserver | grep -v grep",
        "expect": "--audit-policy-file=@AUDIT_POLICY_FILE@([\\\\s]|$)"
    },
    "custom_item_93": {
        "description": "Check if kubectl exists",
        "file": "@KUBECTL_PATH@/kubectl"
    },
    "custom_item_94": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_95": {
        "system": "Linux",
        "description": "5.1.1 Ensure that the cluster-admin role is only used where required",
        "info": "The RBAC role cluster-admin provides wide-ranging powers over the environment and should be used only where and when needed.\n\nRationale:\n\nKubernetes provides a set of default roles where RBAC is used. Some of these roles such as cluster-admin provide wide-ranging privileges which should only be applied where absolutely necessary. Roles such as cluster-admin allow super-user access to perform any action on any resource. When used in a ClusterRoleBinding, it gives full control over every resource in the cluster and in all namespaces. When used in a RoleBinding, it gives full control over every resource in the rolebinding's namespace, including the namespace itself.\n\nImpact:\n\nCare should be taken before removing any clusterrolebindings from the environment to ensure they were not required for operation of the cluster. Specifically, modifications should not be made to clusterrolebindings with the system: prefix as they are required for the operation of system components.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges.\nWhere possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role :\n\nkubectl delete clusterrolebinding [name]\n\nDefault Value:\n\nBy default a single clusterrolebinding called cluster-admin is provided with the system:masters group as its principal.",
        "reference": "800-171|3.1.1,800-171|3.1.5,800-171|3.3.8,800-171|3.3.9,800-53|AC-2,800-53|AC-3,800-53|AC-6,800-53|AC-6(1),800-53|AC-6(7),800-53|AU-9(4),800-53r5|AC-2,800-53r5|AC-3,800-53r5|AC-6,800-53r5|AC-6(1),800-53r5|AC-6(7),800-53r5|AU-9(4),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(d),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.3(d),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|5.1,CSCv8|6.8,CSF|DE.CM-1,CSF|DE.CM-3,CSF|PR.AC-1,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(b),ISO/IEC-27001|A.9.2.1,ISO/IEC-27001|A.9.2.5,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.4,ISO/IEC-27001|A.9.4.5,ISO/IEC-27001|A.12.4.2,ITSG-33|AC-2,ITSG-33|AC-3,ITSG-33|AC-6,ITSG-33|AC-6(1),ITSG-33|AU-9(4),ITSG-33|AU-9(4)(a),ITSG-33|AU-9(4)(b),LEVEL|1M,NESA|M1.1.3,NESA|M1.2.2,NESA|M5.2.3,NESA|M5.5.2,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|AM28,NIAv2|AM31,NIAv2|GS3,NIAv2|GS4,NIAv2|GS8c,NIAv2|NS5j,NIAv2|SM5,NIAv2|SM6,NIAv2|SS13c,NIAv2|SS14e,NIAv2|SS15c,NIAv2|SS29,NIAv2|VL3b,PCI-DSSv3.2.1|7.1.2,PCI-DSSv3.2.1|10.5,PCI-DSSv3.2.1|10.5.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,PCI-DSSv4.0|10.3.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|13.2,QCSC-v1|15.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get clusterrolebindings --kubeconfig @KUBECONFIG@ -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name",
        "expect": "MANUAL_REVIEW"
    },
    "custom_item_96": {
        "system": "Linux",
        "description": "5.1.1 Ensure that the cluster-admin role is only used where required",
        "info": "The RBAC role cluster-admin provides wide-ranging powers over the environment and should be used only where and when needed.\n\nRationale:\n\nKubernetes provides a set of default roles where RBAC is used. Some of these roles such as cluster-admin provide wide-ranging privileges which should only be applied where absolutely necessary. Roles such as cluster-admin allow super-user access to perform any action on any resource. When used in a ClusterRoleBinding, it gives full control over every resource in the cluster and in all namespaces. When used in a RoleBinding, it gives full control over every resource in the rolebinding's namespace, including the namespace itself.\n\nImpact:\n\nCare should be taken before removing any clusterrolebindings from the environment to ensure they were not required for operation of the cluster. Specifically, modifications should not be made to clusterrolebindings with the system: prefix as they are required for the operation of system components.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Identify all clusterrolebindings to the cluster-admin role. Check if they are used and if they need this role or if they could use a role with fewer privileges.\nWhere possible, first bind users to a lower privileged role and then remove the clusterrolebinding to the cluster-admin role :\n\nkubectl delete clusterrolebinding [name]\n\nDefault Value:\n\nBy default a single clusterrolebinding called cluster-admin is provided with the system:masters group as its principal.",
        "reference": "800-171|3.1.1,800-171|3.1.5,800-171|3.3.8,800-171|3.3.9,800-53|AC-2,800-53|AC-3,800-53|AC-6,800-53|AC-6(1),800-53|AC-6(7),800-53|AU-9(4),800-53r5|AC-2,800-53r5|AC-3,800-53r5|AC-6,800-53r5|AC-6(1),800-53r5|AC-6(7),800-53r5|AU-9(4),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(d),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.4.2(f),CN-L3|8.1.4.3(d),CN-L3|8.1.4.11(b),CN-L3|8.1.10.2(c),CN-L3|8.1.10.6(a),CN-L3|8.5.3.1,CN-L3|8.5.4.1(a),CSCv7|5.1,CSCv8|6.8,CSF|DE.CM-1,CSF|DE.CM-3,CSF|PR.AC-1,CSF|PR.AC-4,CSF|PR.DS-5,CSF|PR.PT-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),HIPAA|164.312(b),ISO/IEC-27001|A.9.2.1,ISO/IEC-27001|A.9.2.5,ISO/IEC-27001|A.9.4.1,ISO/IEC-27001|A.9.4.4,ISO/IEC-27001|A.9.4.5,ISO/IEC-27001|A.12.4.2,ITSG-33|AC-2,ITSG-33|AC-3,ITSG-33|AC-6,ITSG-33|AC-6(1),ITSG-33|AU-9(4),ITSG-33|AU-9(4)(a),ITSG-33|AU-9(4)(b),LEVEL|1M,NESA|M1.1.3,NESA|M1.2.2,NESA|M5.2.3,NESA|M5.5.2,NESA|T4.2.1,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.2,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM3,NIAv2|AM23f,NIAv2|AM28,NIAv2|AM31,NIAv2|GS3,NIAv2|GS4,NIAv2|GS8c,NIAv2|NS5j,NIAv2|SM5,NIAv2|SM6,NIAv2|SS13c,NIAv2|SS14e,NIAv2|SS15c,NIAv2|SS29,NIAv2|VL3b,PCI-DSSv3.2.1|7.1.2,PCI-DSSv3.2.1|10.5,PCI-DSSv3.2.1|10.5.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,PCI-DSSv4.0|10.3.2,QCSC-v1|3.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,QCSC-v1|13.2,QCSC-v1|15.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get clusterrolebindings -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name",
        "expect": "MANUAL_REVIEW"
    },
    "custom_item_97": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_98": {
        "system": "Linux",
        "description": "5.1.6 Ensure that Service Account Tokens are only mounted where necessary - serviceaccounts",
        "info": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server\n\nRationale:\n\nMounting service account tokens inside pods can provide an avenue for privilege escalation attacks where an attacker is able to compromise a single pod in the cluster.\n\nAvoiding mounting these tokens removes this attack avenue.\n\nImpact:\n\nPods mounted without service account tokens will not be able to communicate with the API server, except where the resource is available to unauthenticated principals.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.\n\nDefault Value:\n\nBy default, all pods get a service account token mounted in them.",
        "reference": "800-171|3.13.1,800-53|SC-7(10),800-53r5|SC-7(10),CN-L3|8.1.10.6(j),CSCv7|13,CSCv8|3,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(10),LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|33.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get serviceaccounts --kubeconfig @KUBECONFIG@ -A -o=custom-columns=name:.metadata.name,automountServiceAccountToken:.automountServiceAccountToken | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"none\"}'",
        "expect": "none"
    },
    "custom_item_99": {
        "system": "Linux",
        "description": "5.1.6 Ensure that Service Account Tokens are only mounted where necessary - pods",
        "info": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server\n\nRationale:\n\nMounting service account tokens inside pods can provide an avenue for privilege escalation attacks where an attacker is able to compromise a single pod in the cluster.\n\nAvoiding mounting these tokens removes this attack avenue.\n\nImpact:\n\nPods mounted without service account tokens will not be able to communicate with the API server, except where the resource is available to unauthenticated principals.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.\n\nDefault Value:\n\nBy default, all pods get a service account token mounted in them.",
        "reference": "800-171|3.13.1,800-53|SC-7(10),800-53r5|SC-7(10),CN-L3|8.1.10.6(j),CSCv7|13,CSCv8|3,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(10),LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|33.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get pods --kubeconfig @KUBECONFIG@ -A -o=custom-columns=name:.metadata.name,automountServiceAccountToken:.spec.automountServiceAccountToken | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"none\"}'",
        "expect": "none"
    },
    "custom_item_100": {
        "system": "Linux",
        "description": "5.1.6 Ensure that Service Account Tokens are only mounted where necessary - serviceaccounts",
        "info": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server\n\nRationale:\n\nMounting service account tokens inside pods can provide an avenue for privilege escalation attacks where an attacker is able to compromise a single pod in the cluster.\n\nAvoiding mounting these tokens removes this attack avenue.\n\nImpact:\n\nPods mounted without service account tokens will not be able to communicate with the API server, except where the resource is available to unauthenticated principals.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.\n\nDefault Value:\n\nBy default, all pods get a service account token mounted in them.",
        "reference": "800-171|3.13.1,800-53|SC-7(10),800-53r5|SC-7(10),CN-L3|8.1.10.6(j),CSCv7|13,CSCv8|3,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(10),LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|33.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get serviceaccounts -A -o=custom-columns=name:.metadata.name,automountServiceAccountToken:.automountServiceAccountToken | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"none\"}'",
        "expect": "none"
    },
    "custom_item_101": {
        "system": "Linux",
        "description": "5.1.6 Ensure that Service Account Tokens are only mounted where necessary - pods",
        "info": "Service accounts tokens should not be mounted in pods except where the workload running in the pod explicitly needs to communicate with the API server\n\nRationale:\n\nMounting service account tokens inside pods can provide an avenue for privilege escalation attacks where an attacker is able to compromise a single pod in the cluster.\n\nAvoiding mounting these tokens removes this attack avenue.\n\nImpact:\n\nPods mounted without service account tokens will not be able to communicate with the API server, except where the resource is available to unauthenticated principals.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Modify the definition of pods and service accounts which do not need to mount service account tokens to disable it.\n\nDefault Value:\n\nBy default, all pods get a service account token mounted in them.",
        "reference": "800-171|3.13.1,800-53|SC-7(10),800-53r5|SC-7(10),CN-L3|8.1.10.6(j),CSCv7|13,CSCv8|3,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(10),LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.3.2,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|33.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get pods -A -o=custom-columns=name:.metadata.name,automountServiceAccountToken:.spec.automountServiceAccountToken | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"none\"}'",
        "expect": "none"
    },
    "custom_item_102": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_103": {
        "system": "Linux",
        "description": "5.2.1 Ensure that the cluster has at least one active policy control mechanism in place",
        "info": "Every Kubernetes cluster should have at least one policy control mechanism in place to enforce the other requirements in this section. This could be the in-built Pod Security Admission controller, or a third party policy control system.\n\nRationale:\n\nWithout an active policy control mechanism, it is not possible to limit the use of containers with access to underlying cluster nodes, via mechanisms like privileged containers, or the use of hostPath volume mounts.\n\nImpact:\n\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\nDefault Value:\n\nBy default, Pod Security Admission is enabled but no policies are in place.",
        "reference": "800-171|3.1.5,800-53|AC-6,800-53r5|AC-6,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSF|PR.AC-4,CSF|PR.DS-5,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ITSG-33|AC-6,LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get namespaces,validatingwebhookconfigurations,mutatingwebhookconfigurations --kubeconfig @KUBECONFIG@",
        "expect": "^MANUAL_REVIEW$"
    },
    "custom_item_104": {
        "system": "Linux",
        "description": "5.2.1 Ensure that the cluster has at least one active policy control mechanism in place",
        "info": "Every Kubernetes cluster should have at least one policy control mechanism in place to enforce the other requirements in this section. This could be the in-built Pod Security Admission controller, or a third party policy control system.\n\nRationale:\n\nWithout an active policy control mechanism, it is not possible to limit the use of containers with access to underlying cluster nodes, via mechanisms like privileged containers, or the use of hostPath volume mounts.\n\nImpact:\n\nWhere policy control systems are in place, there is a risk that workloads required for the operation of the cluster may be stopped from running. Care is required when implementing admission control policies to ensure that this does not occur.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Ensure that either Pod Security Admission or an external policy control system is in place for every namespace which contains user workloads.\n\nDefault Value:\n\nBy default, Pod Security Admission is enabled but no policies are in place.",
        "reference": "800-171|3.1.5,800-53|AC-6,800-53r5|AC-6,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSF|PR.AC-4,CSF|PR.DS-5,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ITSG-33|AC-6,LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|13.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get namespaces,validatingwebhookconfigurations,mutatingwebhookconfigurations",
        "expect": "^MANUAL_REVIEW$"
    },
    "custom_item_105": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_106": {
        "system": "Linux",
        "description": "5.2.2 Minimize the admission of privileged containers",
        "info": "Do not generally permit containers to be run with the securityContext.privileged flag set to true.\n\nRationale:\n\nPrivileged containers have access to all Linux Kernel capabilities and devices. A container running with full privileges can do almost everything that the host can do. This flag exists to allow special use-cases, like manipulating the network stack and accessing devices.\n\nThere should be at least one admission control policy defined which does not permit privileged containers.\n\nIf you need to run privileged containers, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.containers[].securityContext.privileged: true, spec.initContainers[].securityContext.privileged: true and spec.ephemeralContainers[].securityContext.privileged: true will not be permitted.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of privileged containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of privileged containers.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,privileged:.spec.privileged",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_107": {
        "system": "Linux",
        "description": "5.2.2 Minimize the admission of privileged containers",
        "info": "Do not generally permit containers to be run with the securityContext.privileged flag set to true.\n\nRationale:\n\nPrivileged containers have access to all Linux Kernel capabilities and devices. A container running with full privileges can do almost everything that the host can do. This flag exists to allow special use-cases, like manipulating the network stack and accessing devices.\n\nThere should be at least one admission control policy defined which does not permit privileged containers.\n\nIf you need to run privileged containers, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.containers[].securityContext.privileged: true, spec.initContainers[].securityContext.privileged: true and spec.ephemeralContainers[].securityContext.privileged: true will not be permitted.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of privileged containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of privileged containers.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1M,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,privileged:.spec.privileged",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_108": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_109": {
        "system": "Linux",
        "description": "5.2.3 Minimize the admission of containers wishing to share the host process ID namespace",
        "info": "Do not generally permit containers to be run with the hostPID flag set to true.\n\nRationale:\n\nA container running in the host's PID namespace can inspect processes running outside the container. If the container also has access to ptrace capabilities this can be used to escalate privileges outside of the container.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host PID namespace.\n\nIf you need to run containers which require hostPID, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostPID: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostPID containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostPID containers.",
        "reference": "800-171|3.13.1,800-53|SC-7(8),800-53r5|SC-7(8),CN-L3|8.1.10.6(j),CSCv7|12.9,CSCv8|13.10,CSF|PR.AC-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(8),LEVEL|1A,NESA|T4.5.4,NIAv2|SU4,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.2.1,PCI-DSSv4.0|1.4.1,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|43.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,hostPID:.spec.hostPID",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_110": {
        "system": "Linux",
        "description": "5.2.3 Minimize the admission of containers wishing to share the host process ID namespace",
        "info": "Do not generally permit containers to be run with the hostPID flag set to true.\n\nRationale:\n\nA container running in the host's PID namespace can inspect processes running outside the container. If the container also has access to ptrace capabilities this can be used to escalate privileges outside of the container.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host PID namespace.\n\nIf you need to run containers which require hostPID, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostPID: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostPID containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostPID containers.",
        "reference": "800-171|3.13.1,800-53|SC-7(8),800-53r5|SC-7(8),CN-L3|8.1.10.6(j),CSCv7|12.9,CSCv8|13.10,CSF|PR.AC-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7(8),LEVEL|1A,NESA|T4.5.4,NIAv2|SU4,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.2.1,PCI-DSSv4.0|1.4.1,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|43.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,hostPID:.spec.hostPID",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_111": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_112": {
        "system": "Linux",
        "description": "5.2.4 Minimize the admission of containers wishing to share the host IPC namespace",
        "info": "Do not generally permit containers to be run with the hostIPC flag set to true.\n\nRationale:\n\nA container running in the host's IPC namespace can use IPC to interact with processes outside the container.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host IPC namespace.\n\nIf you need to run containers which require hostIPC, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostIPC: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostIPC containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostIPC containers.",
        "reference": "800-171|3.13.4,800-53|SC-4,800-53r5|SC-4,CSCv7|14.1,CSCv8|3.12,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|SC-4,ITSG-33|SC-4a.,LEVEL|1A",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,hostIPC:.spec.hostIPC",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_113": {
        "system": "Linux",
        "description": "5.2.4 Minimize the admission of containers wishing to share the host IPC namespace",
        "info": "Do not generally permit containers to be run with the hostIPC flag set to true.\n\nRationale:\n\nA container running in the host's IPC namespace can use IPC to interact with processes outside the container.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host IPC namespace.\n\nIf you need to run containers which require hostIPC, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostIPC: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostIPC containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostIPC containers.",
        "reference": "800-171|3.13.4,800-53|SC-4,800-53r5|SC-4,CSCv7|14.1,CSCv8|3.12,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|SC-4,ITSG-33|SC-4a.,LEVEL|1A",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,hostIPC:.spec.hostIPC",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_114": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_115": {
        "system": "Linux",
        "description": "5.2.5 Minimize the admission of containers wishing to share the host network namespace",
        "info": "Do not generally permit containers to be run with the hostNetwork flag set to true.\n\nRationale:\n\nA container running in the host's network namespace could access the local loopback device, and could access network traffic to and from other pods.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host network namespace.\n\nIf you need to run containers which require access to the host's network namespaces, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostNetwork: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostNetwork containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostNetwork containers.",
        "reference": "800-171|3.13.4,800-53|SC-4,800-53r5|SC-4,CSCv7|14.1,CSCv8|3.12,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|SC-4,ITSG-33|SC-4a.,LEVEL|1A",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,hostNetwork:.spec.hostNetwork",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_116": {
        "system": "Linux",
        "description": "5.2.5 Minimize the admission of containers wishing to share the host network namespace",
        "info": "Do not generally permit containers to be run with the hostNetwork flag set to true.\n\nRationale:\n\nA container running in the host's network namespace could access the local loopback device, and could access network traffic to and from other pods.\n\nThere should be at least one admission control policy defined which does not permit containers to share the host network namespace.\n\nIf you need to run containers which require access to the host's network namespaces, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.hostNetwork: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of hostNetwork containers.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of hostNetwork containers.",
        "reference": "800-171|3.13.4,800-53|SC-4,800-53r5|SC-4,CSCv7|14.1,CSCv8|3.12,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|SC-4,ITSG-33|SC-4a.,LEVEL|1A",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,hostNetwork:.spec.hostNetwork",
        "expect": "^.*[\\\\s]$"
    },
    "custom_item_117": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_118": {
        "system": "Linux",
        "description": "5.2.6 Minimize the admission of containers with allowPrivilegeEscalation",
        "info": "Do not generally permit containers to be run with the allowPrivilegeEscalation flag set to true. Allowing this right can lead to a process running a container getting more rights than it started with.\n\nIt's important to note that these rights are still constrained by the overall container sandbox, and this setting does not relate to the use of privileged containers.\n\nRationale:\n\nA container running with the allowPrivilegeEscalation flag set to true may have processes that can gain more privileges than their parent.\n\nThere should be at least one admission control policy defined which does not permit containers to allow privilege escalation. The option exists (and is defaulted to true) to permit setuid binaries to run.\n\nIf you have need to run containers which use setuid binaries or require privilege escalation, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.allowPrivilegeEscalation: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with .spec.allowPrivilegeEscalationset to true.\n\nDefault Value:\n\nBy default, there are no restrictions on contained process ability to escalate privileges, within the context of the container.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,allowPrivilegeEscalation:.spec.allowPrivilegeEscalation",
        "expect": "^.*[\\\\s]false$"
    },
    "custom_item_119": {
        "system": "Linux",
        "description": "5.2.6 Minimize the admission of containers with allowPrivilegeEscalation",
        "info": "Do not generally permit containers to be run with the allowPrivilegeEscalation flag set to true. Allowing this right can lead to a process running a container getting more rights than it started with.\n\nIt's important to note that these rights are still constrained by the overall container sandbox, and this setting does not relate to the use of privileged containers.\n\nRationale:\n\nA container running with the allowPrivilegeEscalation flag set to true may have processes that can gain more privileges than their parent.\n\nThere should be at least one admission control policy defined which does not permit containers to allow privilege escalation. The option exists (and is defaulted to true) to permit setuid binaries to run.\n\nIf you have need to run containers which use setuid binaries or require privilege escalation, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods defined with spec.allowPrivilegeEscalation: true will not be permitted unless they are run under a specific policy.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with .spec.allowPrivilegeEscalationset to true.\n\nDefault Value:\n\nBy default, there are no restrictions on contained process ability to escalate privileges, within the context of the container.",
        "reference": "800-171|3.1.5,800-171|3.1.6,800-53|AC-6(2),800-53|AC-6(5),800-53r5|AC-6(2),800-53r5|AC-6(5),CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.4.2(d),CN-L3|8.1.10.6(a),CSCv7|4,CSCv8|5.4,CSF|PR.AC-4,GDPR|32.1.b,HIPAA|164.306(a)(1),HIPAA|164.312(a)(1),ISO/IEC-27001|A.9.2.3,ITSG-33|AC-6(2),ITSG-33|AC-6(5),LEVEL|1A,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.6.1,NIAv2|AM1,NIAv2|AM23f,NIAv2|AM32,NIAv2|AM33,NIAv2|SS13c,NIAv2|SS15c,NIAv2|VL3a,PCI-DSSv3.2.1|7.1.2,PCI-DSSv4.0|7.2.1,PCI-DSSv4.0|7.2.2,QCSC-v1|5.2.2,QCSC-v1|6.2,SWIFT-CSCv1|1.2,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,allowPrivilegeEscalation:.spec.allowPrivilegeEscalation",
        "expect": "^.*[\\\\s]false$"
    },
    "custom_item_120": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_121": {
        "system": "Linux",
        "description": "5.2.8 Minimize the admission of containers with the NET_RAW capability",
        "info": "Do not generally permit containers with the potentially dangerous NET_RAW capability.\n\nRationale:\n\nContainers run with a default set of capabilities as assigned by the Container Runtime. By default this can include potentially dangerous capabilities. With Docker as the container runtime the NET_RAW capability is enabled which may be misused by malicious containers.\n\nIdeally, all containers should drop this capability.\n\nThere should be at least one admission control policy defined which does not permit containers with the NET_RAW capability.\n\nIf you need to run containers with this capability, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods with containers which run with the NET_RAW capability will not be permitted.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with the NET_RAW capability.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of containers with the NET_RAW capability.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|5.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,requiredDropCapabilities:.spec.requiredDropCapabilities",
        "expect": "^.*[\\\\s]\\\\[.*(ALL|NET_RAW).*\\\\]$"
    },
    "custom_item_122": {
        "system": "Linux",
        "description": "5.2.8 Minimize the admission of containers with the NET_RAW capability",
        "info": "Do not generally permit containers with the potentially dangerous NET_RAW capability.\n\nRationale:\n\nContainers run with a default set of capabilities as assigned by the Container Runtime. By default this can include potentially dangerous capabilities. With Docker as the container runtime the NET_RAW capability is enabled which may be misused by malicious containers.\n\nIdeally, all containers should drop this capability.\n\nThere should be at least one admission control policy defined which does not permit containers with the NET_RAW capability.\n\nIf you need to run containers with this capability, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods with containers which run with the NET_RAW capability will not be permitted.",
        "solution": "Add policies to each namespace in the cluster which has user workloads to restrict the admission of containers with the NET_RAW capability.\n\nDefault Value:\n\nBy default, there are no restrictions on the creation of containers with the NET_RAW capability.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|5.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,requiredDropCapabilities:.spec.requiredDropCapabilities",
        "expect": "^.*[\\\\s]\\\\[.*(ALL|NET_RAW).*\\\\]$"
    },
    "custom_item_123": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_124": {
        "system": "Linux",
        "description": "5.2.9 Minimize the admission of containers with added capabilities",
        "info": "Do not generally permit containers with capabilities assigned beyond the default set.\n\nRationale:\n\nContainers run with a default set of capabilities as assigned by the Container Runtime. Capabilities outside this set can be added to containers which could expose them to risks of container breakout attacks.\n\nThere should be at least one policy defined which prevents containers with capabilities beyond the default set from launching.\n\nIf you need to run containers with additional capabilities, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods with containers which require capabilities with the default set will not be permitted.",
        "solution": "Ensure that allowedCapabilities is not present in policies for the cluster unless it is set to an empty array.\n\nDefault Value:\n\nBy default, there are no restrictions on adding capabilities to containers.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|5.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp --kubeconfig @KUBECONFIG@ -o=custom-columns=name:.metadata.name,allowedCapabilities:.spec.allowedCapabilities | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"all psp policies compliant\"}'",
        "expect": "all psp policies compliant"
    },
    "custom_item_125": {
        "system": "Linux",
        "description": "5.2.9 Minimize the admission of containers with added capabilities",
        "info": "Do not generally permit containers with capabilities assigned beyond the default set.\n\nRationale:\n\nContainers run with a default set of capabilities as assigned by the Container Runtime. Capabilities outside this set can be added to containers which could expose them to risks of container breakout attacks.\n\nThere should be at least one policy defined which prevents containers with capabilities beyond the default set from launching.\n\nIf you need to run containers with additional capabilities, this should be defined in a separate policy and you should carefully check to ensure that only limited service accounts and users are given permission to use that policy.\n\nImpact:\n\nPods with containers which require capabilities with the default set will not be permitted.",
        "solution": "Ensure that allowedCapabilities is not present in policies for the cluster unless it is set to an empty array.\n\nDefault Value:\n\nBy default, there are no restrictions on adding capabilities to containers.",
        "reference": "800-171|3.4.2,800-171|3.4.6,800-171|3.4.7,800-53|CM-6,800-53|CM-7,800-53r5|CM-6,800-53r5|CM-7,CSCv7|5.2,CSCv8|4.8,CSF|PR.IP-1,CSF|PR.PT-3,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,ITSG-33|CM-7,LEVEL|1A,NIAv2|SS15a,PCI-DSSv3.2.1|2.2.2,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get psp -o=custom-columns=name:.metadata.name,allowedCapabilities:.spec.allowedCapabilities | tail -n+2 | grep -v '' | awk '{print} END {if (NR == 0) print \"all psp policies compliant\"}'",
        "expect": "all psp policies compliant"
    },
    "custom_item_126": {
        "description": "Check if kubeconfig exists",
        "file": "@KUBECONFIG@"
    },
    "custom_item_127": {
        "system": "Linux",
        "description": "5.7.1 Create administrative boundaries between resources using namespaces",
        "info": "Use namespaces to isolate your Kubernetes objects.\n\nRationale:\n\nLimiting the scope of user permissions can reduce the impact of mistakes or malicious activities. A Kubernetes namespace allows you to partition created resources into logically named groups. Resources created in one namespace can be hidden from other namespaces. By default, each resource created by a user in Kubernetes cluster runs in a default namespace, called default. You can create additional namespaces and attach resources and users to them. You can use Kubernetes Authorization plugins to create policies that segregate access to namespace resources between different users.\n\nImpact:\n\nYou need to switch between namespaces for administration.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Follow the documentation and create namespaces for objects in your deployment as you need them.\n\nDefault Value:\n\nBy default, Kubernetes starts with two initial namespaces:\n\ndefault - The default namespace for objects with no other namespace\n\nkube-system - The namespace for objects created by the Kubernetes system\n\nkube-node-lease - Namespace used for node heartbeats\n\nkube-public - Namespace used for public information in a cluster",
        "reference": "800-171|3.13.1,800-171|3.13.5,800-53|SC-7,800-53r5|SC-7,CN-L3|8.1.10.6(j),CSCv7|12,CSCv8|13,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7,LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.2.1,PCI-DSSv4.0|1.4.1,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|43.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get namespaces --kubeconfig @KUBECONFIG@",
        "expect": "MANUAL_REVIEW"
    },
    "custom_item_128": {
        "system": "Linux",
        "description": "5.7.1 Create administrative boundaries between resources using namespaces",
        "info": "Use namespaces to isolate your Kubernetes objects.\n\nRationale:\n\nLimiting the scope of user permissions can reduce the impact of mistakes or malicious activities. A Kubernetes namespace allows you to partition created resources into logically named groups. Resources created in one namespace can be hidden from other namespaces. By default, each resource created by a user in Kubernetes cluster runs in a default namespace, called default. You can create additional namespaces and attach resources and users to them. You can use Kubernetes Authorization plugins to create policies that segregate access to namespace resources between different users.\n\nImpact:\n\nYou need to switch between namespaces for administration.\n\nNOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "solution": "Follow the documentation and create namespaces for objects in your deployment as you need them.\n\nDefault Value:\n\nBy default, Kubernetes starts with two initial namespaces:\n\ndefault - The default namespace for objects with no other namespace\n\nkube-system - The namespace for objects created by the Kubernetes system\n\nkube-node-lease - Namespace used for node heartbeats\n\nkube-public - Namespace used for public information in a cluster",
        "reference": "800-171|3.13.1,800-171|3.13.5,800-53|SC-7,800-53r5|SC-7,CN-L3|8.1.10.6(j),CSCv7|12,CSCv8|13,CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,GDPR|32.1.b,HIPAA|164.306(a)(1),ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7,LEVEL|1M,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,PCI-DSSv3.2.1|1.1,PCI-DSSv3.2.1|1.2,PCI-DSSv3.2.1|1.2.1,PCI-DSSv3.2.1|1.3,PCI-DSSv4.0|1.2.1,PCI-DSSv4.0|1.4.1,QCSC-v1|5.2.1,QCSC-v1|5.2.2,QCSC-v1|6.2,QCSC-v1|8.2.1,TBA-FIISB|43.1",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "cmd": "@KUBECTL_PATH@/kubectl get namespaces",
        "expect": "MANUAL_REVIEW"
    },
    "custom_item_129": {
        "system": "Linux",
        "description": "CIS_Kubernetes_v1.23_v1.0.1_Level_1_Master.audit from CIS Kubernetes v1.23 Benchmark v1.0.1",
        "info": "NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance.",
        "reference": "800-171|3.4.2,800-53|CM-6,800-53r5|CM-6,CSF|PR.IP-1,GDPR|32.1.b,HIPAA|164.306(a)(1),ITSG-33|CM-6,SWIFT-CSCv1|2.3",
        "see_also": "https://workbench.cisecurity.org/files/3892",
        "name": "kubelet"
    }
}